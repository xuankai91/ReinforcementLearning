{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPole_Qlearning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tF-HDR8sDBTM"
      ],
      "authorship_tag": "ABX9TyOC/Nm8C/6Xdf5xiI862Ps+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuankai91/ReinforcementLearning/blob/main/CartPole_Qlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztpFLGKtCuvC"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpts9Eo7qHWO",
        "outputId": "7a234f74-d152-408a-b2e6-47a65b7448ed"
      },
      "source": [
        "# install required system dependencies\n",
        "!apt-get install -y xvfb x11-utils\n",
        "!pip install pyvirtualdisplay==0.2.* \\\n",
        "             PyOpenGL==3.1.* \\\n",
        "             PyOpenGL-accelerate==3.1.* \\\n",
        "             gym[box2d]==0.17.*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 994 kB of archives.\n",
            "After this operation, 2,981 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 994 kB in 0s (9,110 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.5)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
            "\u001b[K     |████████████████████████████████| 538 kB 12.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym[box2d]==0.17.* in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.19.5)\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 70.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.16.0)\n",
            "Building wheels for collected packages: PyOpenGL-accelerate\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp37-cp37m-linux_x86_64.whl size=1599572 sha256=7525db45b65cf9c295a8d9d219015e5f340123b81cc050ba820529ccf9e02cf3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/6f/169afb3f2d476c5e807f8515b3c9bc9b819c3962316aa804eb\n",
            "Successfully built PyOpenGL-accelerate\n",
            "Installing collected packages: EasyProcess, box2d-py, pyvirtualdisplay, PyOpenGL-accelerate\n",
            "Successfully installed EasyProcess-0.3 PyOpenGL-accelerate-3.1.5 box2d-py-2.3.8 pyvirtualdisplay-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYNArAT4ug_-",
        "outputId": "c44f7157-59f2-49a8-8a00-585f4c236945"
      },
      "source": [
        "#check that display is working (it has a number)\n",
        "import pyvirtualdisplay\n",
        "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
        "                                    size=(400, 300))\n",
        "_ = _display.start()\n",
        "!echo $DISPLAY"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTzbek5DJgtm"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import gym\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from IPython import display\n",
        "import time\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gzn1TX5Ct0n"
      },
      "source": [
        "# CARTPOLE\n",
        "\n",
        "**About the cartpole environment**\n",
        "* The **State** is a 4-tuple, comprising of\n",
        " 1. Cart Position, $\\in [-2.4,2.4]$\n",
        " 2. Cart Velocity, $\\in [-\\infty,\\infty]$\n",
        " 3. Pole Angle, $\\in [-41.8^{\\circ},41.8^{\\circ}]$\n",
        " 4. Pole Velocity at Tip, $\\in [-\\infty,\\infty]$\n",
        "* Available **Actions** are\n",
        " 1. Push cart to the left, $0$\n",
        " 2. Push cart to the right, $1$\n",
        "* The **Reward** is $+1$ for every step taken, including termination step.\n",
        "* The episode terminates if\n",
        " * Pole Angle falls past $12^{\\circ}$ from the midline.\n",
        " * Cart Position has moved past $\\pm 2.4$\n",
        " * Episode has proceeded for >200 time-steps.\n",
        "  * However I have manually changed the limit to >800 time-steps to better visualise the environment\n",
        "\n",
        "---\n",
        "\n",
        "**About this RL procedure**\n",
        "* As this is a Q-learning implementation, the target $G$ is:\n",
        "$$G=\\begin{cases}\n",
        "r_{t+1}  & t+1 = T \n",
        "\\\\ r_{t+1} + \\gamma \\max_{a_{t+1}}Q(s_{t+1},a_{t+1}) & \\forall t+1 \\not= T \n",
        "\\end{cases}$$\n",
        "where $T$ is the time-step of the terminal state.\n",
        "* Here, I approximate the state-action pair, $s,a$  to a feature vector by:\n",
        " 1. concatenating the state & action into a vector, $(s,a)$\n",
        " 2. expanding the vector via a RBF kernel function, $\\phi(s,a)$\n",
        "* Then I model the state-action value $Q(s,a)$ via a linear function,\n",
        "$$\\hat{Q}_{\\pi}(s,a) = w^{T}\\phi(s,a)$$\n",
        "* The loss function, $J$, for a linear model would be squared-error,\n",
        "$$\\begin{aligned}\n",
        "J &= \\bigl(G - \\hat{Q}_{\\pi}(s,a) \\bigr)^{2}\n",
        "\\\\ &= \\bigl(G - w^{T}\\phi(s,a) \\bigr)^{2}\n",
        "\\end{aligned}$$\n",
        "and, if we let $x = \\phi(s,a)$, the derivative would therefore be\n",
        "$$\\nabla_{w}J = 2(G-w^{T}x)x$$\n",
        "* Using stochastic gradient ascent, I update the model parameters incrementally via\n",
        "$$w \\leftarrow w + \\alpha(G-w^{T}x)x$$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**note**\n",
        "* the RBF kernel function is $\\phi(x) = \\exp \\bigl( - \\beta ||x - x_{i}||^{2}  \\bigr)$, where $x$ is a vector with >1 entry.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCpR3bF_C1L6"
      },
      "source": [
        "# CREATING THE AGENT & HELPER FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhl84jAdqYW6"
      },
      "source": [
        "class CPAgent():\n",
        "  def __init__(self):\n",
        "    self.name = 'CPAgent'\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## STARTUP FUNCTIONS ##\n",
        "\n",
        "  def sample_unknown_environment(self,env,n_eps=10000):\n",
        "    # get environment properties\n",
        "    self.StartingState = env.reset()\n",
        "    self.PreviousState = self.StartingState\n",
        "    self.CurrentState = self.StartingState\n",
        "\n",
        "    # define action space (manually defined)\n",
        "    self.ActionSpace = [0,1]\n",
        "    \n",
        "    # start sampling states, to get a representation of available states\n",
        "    self.Samples = []\n",
        "    for _ in range(n_eps):\n",
        "      s = env.reset()\n",
        "      done = False\n",
        "      while not done:\n",
        "        #draw action\n",
        "        act = env.action_space.sample()\n",
        "        \n",
        "        # record sample\n",
        "        sa = tuple(list(s) + [act])\n",
        "        self.Samples.append(sa)\n",
        "\n",
        "        #play action, get observations:\n",
        "        s, _, done, _ = env.step(act)\n",
        "      \n",
        "      #at terminal state, concatenate into samples but with dummy action\n",
        "      sa = tuple(list(s) + [env.action_space.sample()])\n",
        "      self.Samples.append(sa)\n",
        "  \n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## FUNCTION APPROXIMATION (LINEAR) ##\n",
        "\n",
        "  def approximate_model(self):\n",
        "    self.Featurizer = RBFSampler()\n",
        "    self.Featurizer.fit(self.Samples)\n",
        "    #we initialise weights of the linear model to 0\n",
        "    self.FuncWeights = np.zeros(self.Featurizer.n_components) \n",
        "     \n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## PREDICT Q-VALUES\n",
        "  \n",
        "  def predictQ(self,state,action): \n",
        "    '''\n",
        "    this returns the quantities necessary to calculate the gradient\n",
        "    1. dot product of state-action vector\n",
        "    2. the (RBF transformed) state-action vector\n",
        "    '''\n",
        "    sa = tuple(list(state) + [action])\n",
        "    x = self.Featurizer.transform([sa])[0]\n",
        "    return x @ self.FuncWeights, x\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## POLICY ##\n",
        "  \n",
        "  # epsilon-greedy policy\n",
        "  def epsilon_greedy(self,state, eps=.1):\n",
        "    #for majority of the time\n",
        "    if np.random.rand() < (1 - eps):\n",
        "      #first, get maximum Q-value\n",
        "      values = []\n",
        "      max_val = float('-inf')\n",
        "      for act in self.ActionSpace:\n",
        "        sa = tuple(list(state) + [act])\n",
        "        x = self.Featurizer.transform([sa])[0]\n",
        "        val = x @ self.FuncWeights\n",
        "        values.append((act,val))\n",
        "        max_val = max(val,max_val)\n",
        "      \n",
        "      #then, find actions which are at the maximum value\n",
        "      max_a = []\n",
        "      for act,val in values:\n",
        "        if val == max_val:\n",
        "          max_a.append(act)\n",
        "      \n",
        "      # return best action, with ties broken randomly\n",
        "      return np.random.choice(max_a) \n",
        "\n",
        "    #otherwise random action\n",
        "    else: \n",
        "      return np.random.choice(self.ActionSpace)\n",
        " \n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## RESETS ##\n",
        "  \n",
        "  ## reset agent location back to start\n",
        "  def reset_agent(self,state):\n",
        "    self.CurrentState = state\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X6BVUWtqYZW"
      },
      "source": [
        "#helper functions\n",
        "def watch_agent(agent,env,ax):\n",
        "  done = False\n",
        "  episode_reward = 0\n",
        "  s = env.reset()\n",
        "  img = ax.imshow(env.render(mode='rgb_array'))\n",
        "  while not done:\n",
        "    a = agent.epsilon_greedy(s)\n",
        "    s,r,done,_ = env.step(a)\n",
        "\n",
        "    img.set_data(env.render(mode='rgb_array'))\n",
        "    ax.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    episode_reward += r\n",
        "  print(\"Agent balanced the cartpole for %d steps.\" % episode_reward)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dKNOLeDAlJi"
      },
      "source": [
        "# BALANCING CARTPOLE BY IMPLEMENTING Q-LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYKKjDRfArMg"
      },
      "source": [
        "#setup environment\n",
        "env = gym.make('CartPole-v1')\n",
        "env.theta_threshold_radians = 24 * 2 * math.pi / 360 #change manually degree of pole angle for episode termination (may not work)\n",
        "env._max_episode_steps = 800 #manually increase the number of time steps before episode termination\n",
        "\n",
        "#instantiate agent\n",
        "agent = CPAgent()\n",
        "\n",
        "#set learning hyperparameters\n",
        "GAMMA = 0.95 #discount factor of the return\n",
        "ALPHA = 0.05 #learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "CjhaHAutAxqI",
        "outputId": "1d3b8c98-6375-49bd-aa2e-6c427082e1f0"
      },
      "source": [
        "## let agent explore the environment for a few rounds, just to get a sense of possible state spaces/state-action pairs\n",
        "# first, let agent play a few rounds in the environment\n",
        "agent.sample_unknown_environment(env)\n",
        "\n",
        "#once environment has been sampled, approximate state/action values by a linear function\n",
        "agent.approximate_model()\n",
        "\n",
        "#now, we observe how an untrained agent balances the cartpole. Note that this performace should be bad.\n",
        "_, ax1 = plt.subplots(1, 1)\n",
        "watch_agent(agent,env,ax1)\n",
        "time.sleep(3)\n",
        "env.close() #closes render"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent balanced the cartpole for 13 steps.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "1SwThcuPqiLX",
        "outputId": "d3290e8c-8c30-485f-d8bf-8f929af4f05c"
      },
      "source": [
        "## Agent starts learning here\n",
        "\n",
        "# keep track of reward per episode\n",
        "reward_per_episode = []\n",
        "\n",
        "#let agent learn over 2,000 episodes\n",
        "for it in range(2000):\n",
        "\n",
        "  #reset before every episode\n",
        "  s = env.reset()\n",
        "  agent.reset_agent(s)\n",
        "  done = False\n",
        "  \n",
        "  #start playing\n",
        "  episode_reward = 0\n",
        "  while not done:\n",
        "    #keep record of previous state\n",
        "    agent.PreviousState = agent.CurrentState\n",
        "\n",
        "    #get action\n",
        "    action = agent.epsilon_greedy(agent.CurrentState) #action from current state (according to policy)\n",
        "\n",
        "    #get next state, move & obtain reward\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    agent.CurrentState = next_state #update agent's representation of the new state\n",
        "    \n",
        "    # get target\n",
        "    if done:\n",
        "      target = reward\n",
        "    else:\n",
        "      Qs2 = []\n",
        "      for next_action in agent.ActionSpace: # loop through all actions to obtain all possible values of Q(s',a')\n",
        "        tempQ, _ = agent.predictQ(agent.CurrentState,next_action)\n",
        "        Qs2.append(tempQ) \n",
        "      target = reward + GAMMA * max(Qs2)\n",
        "\n",
        "    # update model parameters of the state-value approximator\n",
        "    Qs, svec = agent.predictQ(agent.PreviousState,action) #svec is state-vector from previous state & action\n",
        "    agent.FuncWeights += ALPHA * (target - Qs) * svec #the gradient is (target - Qs) * svec\n",
        "\n",
        "    # accumulate reward & state visit counts\n",
        "    episode_reward += reward\n",
        "\n",
        "  #end of episode\n",
        "  reward_per_episode.append(episode_reward)\n",
        "\n",
        "  #early exit if model has trained sufficiently\n",
        "  if it > 20 and np.mean(reward_per_episode[-20:]) >= 400:\n",
        "    print('Early exit')\n",
        "    break\n",
        "\n",
        "# plot reward over time\n",
        "_ = plt.plot(reward_per_episode)\n",
        "_ = plt.title('plot of reward per episode')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early exit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2dAwah0rBXFr",
        "outputId": "e3cc2c18-dcb0-4efd-d2b1-90e1c7b0bda6"
      },
      "source": [
        "#now, we observe how the trained agent balances the cartpole. \n",
        "_, ax2 = plt.subplots(1, 1)\n",
        "watch_agent(agent,env,ax2)\n",
        "time.sleep(3)\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent balanced the cartpole for 800 steps.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF-HDR8sDBTM"
      },
      "source": [
        "# MISCELLANEOUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apgP5ufl880P"
      },
      "source": [
        "Other approaches to try\n",
        "\n",
        "1. MC learning, SARSA\n",
        "2. Predict $\\hat{Q}(s,a) = w^{T}\\phi(s)$, and the prediction is a vector of the number of discrete action, i.e. $\\hat{Q}(s,a) \\in \\Bbb{R}^{|\\mathcal{A}|}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5fFozMzwUc5"
      },
      "source": [
        "def test_agent(agent,env,n_episodes = 20):\n",
        "  reward_per_episode = np.zeros(n_episodes)\n",
        "  for it in range(n_episodes):\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "    s = env.reset()\n",
        "    while not done:\n",
        "      a = agent.epsilon_greedy(s,eps=0) #entirely greedy\n",
        "      s,r,done,_ = env.step(a)\n",
        "      episode_reward += r\n",
        "    reward_per_episode[it] = episode_reward\n",
        "  return np.mean(reward_per_episode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap0W4Orm5Q4L"
      },
      "source": [
        "# credits\n",
        "\n",
        "\n",
        "https://www.udemy.com/artificial-intelligence-reinforcement-learning-in-python"
      ]
    }
  ]
}