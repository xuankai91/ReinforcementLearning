{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GridWorld_RL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-PIN-I4J9ep0",
        "hnoQzEHv9sGf",
        "Yv4rl4KcWxFY",
        "UdlR0WefW0_A",
        "4PsiWN8OQ1qP",
        "g-oFYQQAwflq",
        "1ENRSzsna1L8",
        "MmiRQH7Uf-Z_",
        "9Mc4MWoxRVyn",
        "2erpfAPswh5X",
        "yoO-BdbhR6GM",
        "T1J_EUBdSFvP",
        "UeW0A007d508",
        "mEoUiAYzdbO2",
        "m99YKNwvdmJc",
        "6qlbFLbBzT9A",
        "oU7vz4rDh_QP",
        "1RjthkW1ltkr",
        "Ew_S6u8ShUIv",
        "CprD3tVhhWDw",
        "_rW2WK4qhvSl",
        "-zBPMlU_hyTp",
        "lx69tK2GijUy",
        "-bZKAc7qilY6",
        "ebxyOpF8ul7Y",
        "flV7mllUnqjC",
        "Wx7lc8ruOHOd",
        "QM1tbesuB9Ri",
        "9RPIWE4BueNz",
        "y9wMScOuuiFd",
        "4x8hc4qAaJFZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "13dI6H7BYrv_"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import gym\n",
        "from sklearn.kernel_approximation import RBFSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FdYcfFFWJ_8"
      },
      "source": [
        "# **REINFORCEMENT LEARNING**\n",
        "\n",
        "![MDP.png](data:image/png;base64,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)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJL4mcR1W3b4"
      },
      "source": [
        "* Unlike multi-armed bandits, in RL, the states are non-stationary. This means that, for every action taken by the agent, the environment transitions to a different state.\n",
        "* RL is active, goal-directed learning, without examples of optimal behaviour. Behaviour is learned by, often sequential, interactions with our environment, and by optimising a reward signal.\n",
        "* The goal of the RL agent is to maximise the total expected reward, for every state, by picking suitable actions.\n",
        "\n",
        "---\n",
        "\n",
        "**Key Terms to remember in RL:**\n",
        "\n",
        "1. Agent and the Environment \n",
        "1. State Space, $\\mathcal{S}$ and Action Space, $\\mathcal{A}$ \n",
        "1. What is an Episode, and its Terminal state, $S_{T}$\n",
        "1. Values (state-values and action-values) and Policies\n",
        "1. Deterministic vs Probabilistic policies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnoQzEHv9sGf"
      },
      "source": [
        "# **MARKOV DECISION PROCESSES**\n",
        "\n",
        "*   An MDP is a discrete-time stochastic control process. It provides a useful mathematical framework for RL.\n",
        "*   Comprises of 2 entities: an **_Agent_** and an **_Environment_**. We build the Agent.\n",
        "*   The agent takes an **_Action_** in the environment, and the environment returns a **_Reward_**, bringing the agent to the next **_State_**.\n",
        "*   The **_Transition_** (i.e. a step in the MDP) can be thought of as a tuple $(S_{t},A_{t},R_{t+1},S_{t+1})$. Note that the time-steps indices are implicit to the environment, and not the agent, especially w.r.t. the reward.\n",
        "*   Both entities are represented as probability distributions:\n",
        " *  Agent: $A_{t} \\sim \\pi(a|s)$\n",
        " *  Environment: $S_{t+1},R_{t+1} \\sim p(s',r|s,a)$\n",
        " *  Note that capitalised letters represent the random variable, and lower case letters represent a specific realisation. $\\pi$ and $p$ represent distributions.\n",
        "*   Rewards can be random, and not deterministic (c.f. $p(s'|s,a)$ when reward is deterministic, as compared to $p(s',r|s,a)$ when reward is random). You may not get the same reward all the time, even if you were to take the same action repeatedly at the same state ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv4rl4KcWxFY"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m75p2SCUJZ3I"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "**Markov Property**\n",
        "* The Markov property states that:\n",
        "$$P(S_{t}|S_{t-1},S_{t-2},S_{t-3},...,S_{0})=P(S_{t}|S_{t-1})$$\n",
        "\n",
        "*   This is called the **_first order Markov assumption_**, as it only considers $S_{t-1}$. Second order implies the consideration of  $S_{t-1}$ & $S_{t-2}$, and so forth.\n",
        " * In other words, the entire history of all previous occurring states is encapsulated within the most recent preceeding state itself.\n",
        "*   Note that a state can be broadly defined, i.e. it does not have to be only the observation at one point in time. See next section for what engenders a state.\n",
        "*   Conceptually, one can approximate state transitions in MDPs as the count of the number of transitions from state $i$ to state $j$ that occur when at state $i$; \n",
        "$$P(S_{t}=j|S_{t-1}=i) \\approx \\frac{\\sum \\Bbb{I}\\{S_{t-1}=i \\ \\to \\ S_{t}=j\\}}{\\sum \\Bbb{I}\\{S_{t-1}=i\\}}$$\n",
        "though there is no practical need to do this counting in RL.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Return**\n",
        "* We call the sum of future rewards the **_Return_**, $G_{t}$.\n",
        "* The goal of the agent is to maximise the sum of future rewards at any given moment. \n",
        " * This is because our future actions can't affect the past, and can only affect the future. \n",
        " * However, the signal for the reward can be very far in the future, so the agent has to learn a plan, which is what RL does by maximising the return. \n",
        "* We also need to discount future rewards, because: \n",
        " * immediate rewards are usually more useful than future rewards\n",
        " * future rewards are harder to predict accurately\n",
        " * returns would have an infinite horizon if we weight all rewards equally (though this would be the true sum of future rewards)\n",
        "* Therefore we define <center>$$G_{t} = \\sum_{\\tau=0}^{\\infty} \\gamma^{\\tau} R_{t+1+\\tau}$$</center> where $\\gamma \\in [0,1] $ represents the discount factor, and is a hyperparameter. Note that as $R_{t}$ is a random variable, thus $G_{t}$ - as a sum of random variables - will also be a random variable.\n",
        "* We also define the terminal state $S_{T}$ as a state that determinsitically and infinitely loops back on itself, i.e. $p(S_{T}|S_{T})=1$, with a reward of $0$. Therefore, even though we sum returns to infinity, any sum after the terminal state would be $0$.\n",
        "\n",
        "---\n",
        "\n",
        "**Choosing Rewards**\n",
        "\n",
        "*   When choosing rewards, pick rewards properly. Note that the agent is not subject to real-life rewards; i.e. it doesn't conceptualise \"winning\" and \"losing\", it just views rewards in a numerical, relative stance. \n",
        "*   For example, rewards of $-1$ entices agent to find the shortest route in a gridworld (or maze), but agent doesn't comprehend the negative reward as \"losing\" (in a broad sense).\n",
        "*   It is also not necessary to reward an agent for only learning human-known strategies, as otherwise it would not be able to find novel but equally effective strategies.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdlR0WefW0_A"
      },
      "source": [
        "## Gridworld\n",
        "\n",
        "* Gridworld is a useful beginner example for implementing RL algorithms, because it has \n",
        " * discrete state spaces\n",
        " * discrete actions\n",
        " * completely known (fully observable) environment dynamics, i.e. how exactly state transitions occur. \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4M1Eoe7xqyM"
      },
      "source": [
        "![gridworld3x4.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMsAAACbCAIAAABDF/iTAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAHYcAAB2HAY/l8WUAAAQCSURBVHhe7d3RbdtIAEVR15WCUseWkCq2BFfivy3GS5oDJjYc4PGJFgfWOTCgEZQYD6MLI/mxnl7hKymMr7UW9gRne3l5eVfY9mQqVuXWt/Sfd1/jhevsF7U+eC9z066aKq/FflHrg/cyN+2qqfJa7Be1Pngvc9OumiqvxX5R64P3MjftqqnyWuwXtT54L3NWhRRWsiqksJJVIYWVrAoprGRVSGElq0IKK1kVUljJqpDCSlaFFFayKqSwklUhhZWsCimsZFVIYaXHWvXfrx/Lt376+TyeH7BPWh8e69Zu8zirRl0rhd3Rg6x6/rl8y6cfv57fMlPYHX2nVW8/pT6tZw3s7YXtB5nC7ug7rfp7YTuF3d13WqUwq1LdKoVZlTqwavs3/Kc+CUlhd/edVvkZZlWqW6Uwq1LdKoVZlepWKcyq1Nmr/vLfgSOlLX98HP58MhWrchOuUljJqpDCSlaFFFayKqSwklUhhZWsCimsZFVIYSWrQgorWRVSWMmqkMJKVoUUVrIqpLCSVSGFlawKKaxkVUhhJatCCitZFVJYyarQx8LgdO8K255MZVn173ymvavt0//2r/HCdfaLUtgx097VVHkt9otS2DHT3tVUeS32i1LYMdPe1VR5LfaLUtgx097VVHkt9otS2DHT3tU4TUNhJYWFFFZSWEhhJYWFFFZSWEhhJYWFFFZSWEhhJYWFFFZSWEhhJYWFFFZSWEhhJYWFFFZSWEhhpUcpbPs159XvOd/skxR2zLR3NU5nGHWtFHZ3097VON3s9k/H3eyTFHbMtHc1Trc64dNxN/skhR0z7V2N02kUdpFp72qcTqOwi0x7V+N0GoVdZNq7GqfTKOwi097VOIU+fPjaJyEp7CLT3tU4nUZhF5n2rsbpNAq7yLR3NU6nUdhFpr2rcbrVCZ+Ou1n+0jj8+WQqy6rxrs5k2rsap2korKSwkMJKCgsprKSwkMJKCgsprKSwkMJKCgsprKSwkMJKCgsprKSwkMJKCgsprKSwkMJKCgsprKSwkMJKCgsprKSwkMJKCgsprKSw0MfC4HTvCtueTMWq3ISrFFayKqSwklUhhZWsCimsZFVIYSWrQgorWRVSWMmqkMJKVoUUVrIqpLCSVSGFlawKKaxkVUhhJatCCitZFVJYyaqQwkpWhRRWsiqksJJVIYWVrAoprGRVSGElq0IKK1kVUljJqpDCSlaFFFayKqSwklUhhZWsCimsZFVIYSWrQgorWRVSWMmqkMJKVoUUVrIqpLCSVSGFlawKKaxkVUhhJatCCitZFVJYyaqQwkpWhRRWsiqksJJVIYWVrAoprGRVSGElq0IKK1kVUljJqtDHwuB0vwuDr6MwvpbC+Eqvr/8D7gZcH6w8P4IAAAAASUVORK5CYII=)\n",
        "\n",
        "Fig 1. Gridworld\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PsiWN8OQ1qP"
      },
      "source": [
        "## Bellman Equations\n",
        "\n",
        "* Given an MDP, the equations allow us to solve for value functions for any policy. All RL algorithms aim to solve the value functions.\n",
        "---\n",
        "**Value Functions**\n",
        "* In general, the return is dependent on the policy and also the current state.\n",
        " * In the Gridworld example (Fig. 1), states (i.e. locations) closer to the goal of $+1$ will have higher returns than states further away (assuming $\\gamma < 1$).\n",
        "* As the return is a random variable (and not deterministic), what we can realistically do is to maximise the _expected_ return. There are 2 approaches for this:\n",
        " * **_State value function_**: $\\; V_{\\pi}(s) = \\Bbb{E_{\\pi}}[G_{t}|S_{t} = s]$\n",
        " * **_Action (or state-action) value function_**: $\\; Q_{\\pi}(s,a) = \\Bbb{E_{\\pi}}[G_{t}|S_{t} = s, A_{t} = a]$\n",
        "\n",
        "* In other words, the value function is the expected cumulative reward (i.e. the return) from a state $s$ at time $t$ (and taking action $a$), under the policy distribution $\\pi$.\n",
        " * Note that the value of a terminal state is always $0$.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-oFYQQAwflq"
      },
      "source": [
        "**State value functions**\n",
        "*  Note that returns can be written in a recursive manner, $G_{t} = R(t+1) +  \\gamma G_{t+1}$\n",
        "*  Since the return is recursive, we rewrite the value function recursively as $$\\begin{aligned} \n",
        "V_{\\pi}(s) &= \\Bbb{E_{\\pi}}[R_{t+1} + \\gamma G_{t+1}|S_{t} = s] \n",
        "\\\\ &= \\Bbb{E_{\\pi}}[R_{t+1}+\\gamma V_{\\pi}(s')|S_{t} = s]\n",
        "\\end{aligned}$$\n",
        " * see proof below to show why expectations are equivalent.\n",
        "* This means that calculating the value of the current state depends only on the next possible state; there is no need to traverse a (possibly infinite) number of future trajectories.\n",
        "*  The expecation thus needs to sum over the distributions $a$, $s'$ & $r$\n",
        "$$V_{\\pi}(s) = \\sum_{a} \\pi(a|s) \\sum_{s'} \\sum_{r} p(s',r|s,a)\\bigl(r+\\gamma V_{\\pi}(s')\\bigr)$$\n",
        "*  Solving the Bellman equations is simply solving a system of linear equations. Unfortunately, it does not scale up to larger number of states.\n",
        "\n",
        "---\n",
        "\n",
        "**State-Action value functions**\n",
        "*  Instead of finding the value function of just the state, we can also attempt to find the value function of a state-action pair (a.k.a. the **_State-Action value function_**) $$Q_{\\pi}(s,a) =\\Bbb{E_{\\pi}}[G_{t}|S_{t} = s,A_{t} = a]$$\n",
        " *  Note that $V_{\\pi}(s) = \\sum_{a} \\pi(a|s) Q_{\\pi}(s,a)$\n",
        "* Similarly, we can write $Q_{\\pi}$ recursively\n",
        "$$\\begin{aligned} \n",
        "Q_{\\pi}(s,a) &= \\Bbb{E_{\\pi}}[R_{t+1} + \\gamma G_{t+1}|S_{t} = s, A_{t}=a] \n",
        "\\\\ &= \\Bbb{E_{\\pi}}[R_{t+1}+\\gamma \\sum_{a'} \\pi(a'|s') Q_{\\pi}(s',a') \\ |\\ S_{t} = s, A_{t}=a]\n",
        "\\end{aligned}$$\n",
        "* Also, similarly, this means that calculating the value of the current state-action pair only depends upon all possible actions available in the next state (and not upon all possible actions).\n",
        "\n",
        "---\n",
        "\n",
        "**Misc**\n",
        "*  When to use $V_{\\pi}(s)$ and $Q_{\\pi}(s,a)$?\n",
        " *  $V_{\\pi}(s)$ is useful for evaluating a policy, i.e. given a policy, what is the return I can expect?\n",
        " * $Q_{\\pi}(s,a)$ is useful for control, or comparison of actions to take, i.e. in state $s$, what is the best action $a$ to take?\n",
        "* Nuances\n",
        " * As an intelligent agent, the policy tells me _what action to do_; _not where to go_.\n",
        " * $p(s',r|s,a)$ tells me _where I end up_, though this, in practical situations, is generally unknown.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY-wRZxnRSHY"
      },
      "source": [
        "**Bellman Equation in matrix form**\n",
        "\n",
        "\n",
        "For any given policy $\\pi$, we can express the value matrix $v$ as\n",
        "$$ \\mathbf{v} = \\mathbf{r} + \\gamma \\mathbf{P} \\mathbf{v} $$\n",
        "\n",
        "\\\n",
        "Where \n",
        "$$\\begin{aligned}\n",
        "{v}_{i} &= V(S_{i}) \\\\\n",
        "{r}_{i} &= \\Bbb{E}[R_{t+1}|S_{t}=s,A_{t} \\sim \\pi(S_{t})] \\\\\n",
        "{P}_{ij} &= p(s_{j}|s_{i}) = \\sum_{a} \\pi(a|s_{i})p(s_{j}|s_{i},a)\n",
        "\\end{aligned}$$\n",
        "\n",
        "\\\n",
        "So it can be solved directly by\n",
        "$$\\begin{aligned}\n",
        "\\mathbf{v} &= \\mathbf{r} + \\gamma \\mathbf{P} \\mathbf{v} \\\\\n",
        "(\\mathbf{I} - \\gamma \\mathbf{P})\\mathbf{v} &= \\mathbf{r} \\\\\n",
        "\\mathbf{v} &= (\\mathbf{I} - \\gamma \\mathbf{P})^{-1}\\mathbf{r}\n",
        "\\end{aligned}$$\n",
        "\n",
        "With a computational complexity of $O(\\vert \\mathcal{S} \\vert ^{3})$\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ENRSzsna1L8"
      },
      "source": [
        "### PROOFS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO-PCMchWikv"
      },
      "source": [
        "\n",
        "**proof of Bellman equation for State value function**\n",
        "$$\\begin{aligned} \n",
        "V_{\\pi}(s) &= \\Bbb{E_{\\pi}}[R_{t+1} + \\gamma G_{t+1}|S_{t} = s] \n",
        "\\\\ &= \\Bbb{E_{\\pi}}[R_{t+1}|S_{t} = s] + \\gamma \\Bbb{E_{\\pi}}[G_{t+1}|S_{t} = s] \n",
        "\\\\ &= \\Bbb{E_{\\pi}}[R_{t+1}|S_{t} = s] + \\gamma \\Bbb{E_{\\pi}}\\bigl[\\Bbb{E_{\\pi}}[G_{t+1}|S_{t+1} = s']|S_{t} = s \\bigr] \n",
        "\\\\ &= \\Bbb{E_{\\pi}}[R_{t+1}|S_{t} = s] + \\gamma \\Bbb{E_{\\pi}}[V_{\\pi}(s')|S_{t} = s] \n",
        "\\\\ &= \\Bbb{E_{\\pi}}[R_{t+1}+\\gamma V_{\\pi}(s')|S_{t} = s]\n",
        "\\end{aligned}$$\n",
        "\n",
        "Note that due to the law of total expectation, $\\Bbb{E}\\bigl[\\Bbb{E}[X|Y]\\bigr] = \\Bbb{E}[X]$, both expectations below are equivalent:\n",
        "$$\\Bbb{E_{\\pi}}[G_{t+1}|S_{t} = s] = \\Bbb{E_{\\pi}}\\bigl[\\Bbb{E_{\\pi}}[G_{t+1}|S_{t+1} = s']|S_{t} = s \\bigr]$$\n",
        "\n",
        "---\n",
        "**proof of Bellman equation for State-Action value function**\n",
        "$$\\begin{aligned} \n",
        "Q_{\\pi}(s,a) &= \\Bbb{E_{\\pi}}[R_{t+1} + \\gamma G_{t+1}|S_{t} = s, A_{t}=a] \n",
        "\\\\ &= \\Bbb{E_{\\pi}} \\bigl[R_{t+1} + \\gamma \\Bbb{E_{\\pi}}[G_{t+1}|S_{t+1}=s']|S_{t} = s, A_{t}=a \\bigr] \n",
        "\\\\ &= \\Bbb{E_{\\pi}} \\bigl[R_{t+1} + \\gamma \\sum_{a'} \\pi(a'|s') \\Bbb{E_{\\pi}}[G_{t+1}|S_{t+1}=s',A_{t+1}=a']|S_{t} = s, A_{t}=a \\bigr] \n",
        "\\\\ &= \\Bbb{E_{\\pi}}[R_{t+1}+\\gamma \\sum_{a'} \\pi(a'|s') Q_{\\pi}(s',a')|S_{t} = s, A_{t}=a]\n",
        "\\end{aligned}$$\n",
        "\n",
        "---\n",
        "**Proof of Law of Total Expectation**\n",
        "\n",
        "<center>$$\\begin{aligned} \n",
        "\\Bbb{E}\\bigl[\\Bbb{E}[X|Y]\\bigr] &= \\Bbb{E} \\Biggl[\\sum_{x} x p(x|Y) \\Biggr]\n",
        "\\\\ &= \\sum_{y} \\Biggl[\\sum_{x} x p(x|y) \\Biggr] p(y)\n",
        "\\\\ &= \\sum_{y} \\sum_{x} x p(x|y) p(y)\n",
        "\\\\ &= \\sum_{y} \\sum_{x} x p(x,y)\n",
        "\\\\ &= \\sum_{x} x \\sum_{y} p(x,y)\n",
        "\\\\ &= \\sum_{x}p(x)\n",
        "\\\\ &= \\Bbb{E}[X]\n",
        "\\end{aligned}$$</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmiRQH7Uf-Z_"
      },
      "source": [
        "## Example of solving an MDP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e4XO9PhATq4"
      },
      "source": [
        "![transition1.png](data:image/png;base64,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)\n",
        "\n",
        "Fig 2. Example of MDP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcnBVSQygouZ"
      },
      "source": [
        "Using the example from Fig 2, we first note down the transition probabilities\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{array}{c|ccc}\n",
        "From/To & S_{1} & S_{2} & S_{3} \\\\\n",
        "\\hline\n",
        "S_{1} & 0.3 & 0.7 & 0 \\\\\n",
        "S_{2} & 0.6 & 0 & 0.4 \\\\\n",
        "S_{3} & 0 & 0 & 0^{*}\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "*technically $p(S_{3}|S_{3})$ is 1, since it is a terminal state, and will always recur onto itself.\n",
        "\n",
        "\\\n",
        "We can then write down the values of each state in terms of the other states\n",
        "\n",
        "$$\\begin{aligned}\n",
        "V(S_{1}) &= p(s1|s1)(R_{1} + \\gamma V(S_{1})) + p(s2|s1)(R_{2} + \\gamma V(S_{2})) + p(s3|s1)(R_{3} + \\gamma V(S_{3}))\n",
        "\\\\ V(S_{2}) &= p(s1|s2)(R_{1} + \\gamma V(S_{1})) + p(s2|s2)(R_{2} + \\gamma V(S_{2})) + p(s3|s2)(R_{3} + \\gamma V(S_{3}))\n",
        "\\\\ V(S_{3}) &= p(s1|s3)(R_{1} + \\gamma V(S_{1})) + p(s2|s3)(R_{2} + \\gamma V(S_{2})) + p(s3|s3)(R_{3} + \\gamma V(S_{3}))\n",
        "\\end{aligned}$$\n",
        "\n",
        "\\\n",
        "We however know that $V(S_{3})=0$, and by substituting in known values of $p(s'|s)$, $R_{t}$ and $\\gamma = 0.9$ to the RHS, it simplifies to\n",
        "\n",
        "$$\\begin{aligned}\n",
        "V(S_{1}) &= 0.3(-0.1 + \\gamma V(S_{1})) + 0.7(-0.1 + \\gamma V(S_{2})) + 0(1 + \\gamma V(S_{3}))\n",
        "\\\\ V(S_{2}) &= 0.6(-0.1 + \\gamma V(S_{1})) + 0(-0.1 + \\gamma V(S_{2})) + 0.4(1 + \\gamma V(S_{3}))\n",
        "\\\\ V(S_{3}) &= 0\n",
        "\\end{aligned}$$\n",
        "\n",
        "\\\n",
        "Bringing all unknowns to the RHS\n",
        "$$\\begin{aligned}\n",
        "0.1 &= -0.73 \\cdot V(S_{1}) + 0.63 \\cdot V(S_{2}) + 0 \\cdot V(S_{3})\n",
        "\\\\ -0.34 &= 0.54 \\cdot V(S_{1}) + (-1) \\cdot V(S_{2}) + 0.36 \\cdot V(S_{2})\n",
        "\\\\ 0 &= 0 \\cdot V(S_{1}) + 0 \\cdot V(S_{2}) + 1 \\cdot V(S_{3})\n",
        "\\end{aligned}$$\n",
        "\n",
        "\\\n",
        "In matrix form, this would be\n",
        "$$\\begin{equation*}\n",
        "\\begin{bmatrix}\n",
        "-0.73 & 0.63 & 0 \\\\\n",
        "0.54 & -1 & 0.36 \\\\\n",
        "0 & 0 & 1\n",
        "\\end{bmatrix} \n",
        "\\begin{bmatrix}\n",
        "V(S_{1}) \\\\\n",
        "V(S_{2}) \\\\\n",
        "V(S_{3})\n",
        "\\end{bmatrix} \n",
        "=\n",
        "\\begin{bmatrix}\n",
        "0.1 \\\\\n",
        "-0.34 \\\\\n",
        "0\n",
        "\\end{bmatrix} \n",
        "\\end{equation*}$$\n",
        "\n",
        "\\\n",
        "Solving for the unknowns (using `np.linalg.solver(A,b)`) gives\n",
        "$$\\begin{equation*}\n",
        "\\begin{bmatrix}\n",
        "V(S_{1}) \\\\\n",
        "V(S_{2}) \\\\\n",
        "V(S_{3})\n",
        "\\end{bmatrix} \n",
        "=\n",
        "\\begin{bmatrix}\n",
        "0.293 \\\\\n",
        "0.498 \\\\\n",
        "0\n",
        "\\end{bmatrix} \n",
        "\\end{equation*}$$\n",
        "\n",
        "---\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG8vNNKT9t9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6281fd-aa5f-4f93-c60f-c8d4df126661"
      },
      "source": [
        "#solving MDP of Fig 2.\n",
        "\n",
        "A = np.array([[-0.73,0.63,0],\n",
        "              [0.54,-1,0.36],\n",
        "              [0,0,1]])\n",
        "\n",
        "b = np.array([[0.1],\n",
        "              [-0.34],\n",
        "              [0]])\n",
        "\n",
        "x = np.linalg.solve(A,b)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29297075]\n",
            " [0.49820421]\n",
            " [0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mc4MWoxRVyn"
      },
      "source": [
        "## Optimal Policy\n",
        "\n",
        "*  A policy can only be considered optimal if it is greater than, or equal to, another policy if and only if its value function is greater than or equal to other value functions, for every state in the state space\n",
        "$$ \\pi^{*} \\geq \\pi^{n} \\iff V_{\\pi^{*}}(s) \\geq V_{\\pi^{n}}(s), \\forall s \\in \\mathcal{S}$$\n",
        "*  This means that\n",
        "$$\\begin{aligned}\n",
        "V^{*}(s) &= \\max_{\\pi} V_{\\pi}(s), \\forall s \\in \\mathcal{S} \\\\\n",
        "\\pi^{*} &= \\arg \\max_{\\pi} V_{\\pi}(s), \\forall s \\in \\mathcal{S} \\\\\n",
        "Q^{*}(s,a) &= \\max_{\\pi} Q_{\\pi}(s,a), \\forall s \\in \\mathcal{S}, \\forall a \\in \\mathcal{A}\n",
        "\\end{aligned}$$\n",
        "*  While we can simply find $\\pi^{*}$ by looping through all possible policies, this is computationally intractable as the number of possible policies are $\\vert \\mathcal{A} \\vert ^{\\vert \\mathcal{S} \\vert}$\n",
        " * For our Gridworld example, Fig 1., it means that the number of policies are $4^{11} \\approx 4.2 \\times 10^{6}$\n",
        "* Rule: Optimal value function is unique, optimal policy is not\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYM6uq3lIIpZ"
      },
      "source": [
        "\n",
        "\n",
        "**Bellman Optimality Equation**\n",
        "*  To find the optimal value of a state, instead of averaging all possible action, we take the best action - the one that yields maximum value:\n",
        "$$ V^{*}(s) = \\max_{a} \\sum_{s'} \\sum_{r} p(s',r|s,a)[r + \\gamma V^{*}(s')] $$\n",
        "*  Similarly, for the optimal state-action:\n",
        "$$ Q^{*}(s,a) = \\sum_{s'} \\sum_{r} p(s',r|s,a)[r + \\gamma \\max_{a'} Q^{*}(s',a')] $$\n",
        "*  So we can relate both values as follows:\n",
        "$$ V^{*}(s) = \\max_{a} Q^{*}(s,a) $$\n",
        "*  Since we can find the action that leads to the best value, the optimal policy is then:\n",
        "\n",
        "$$\\begin{aligned} \n",
        "\\pi^{*}(s) &= \\arg \\max_{a} \\sum_{s'} \\sum_{r} p(s',r|s,a)[r + \\gamma V^{*}(s')] \\\\\n",
        "&= \\arg \\max_{a} Q^{*}(s,a)\n",
        "\\end{aligned}$$\n",
        "*  Deciding whether to use $V^{*}(s)$ or $Q^{*}(s,a)$ to find $\\pi^{*}$ is a recurring theme of the prediction vs control problem.\n",
        " * Prediction/Evaluation problem: How do we find $V(s)$ for a given policy?\n",
        " * Control problem: How to find the optimal policy by finding $Q^{*}$?\n",
        "\n",
        " ---\n",
        " \n",
        " ---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2erpfAPswh5X"
      },
      "source": [
        "# **Dynamic Programming**\n",
        "\n",
        "* Dynamic programming refers to a collection of algorithms that can be used\n",
        "to compute optimal policies given a perfect model of the environment as a\n",
        "MDP.\n",
        "* For every RL algorithm, ask 2 questions:\n",
        " 1. How good is the given policy? (the **_Prediction Problem_**)\n",
        " 2. What is the best policy? (the **_Control Problem_**)\n",
        "* Use **_policy evaluation_** for the prediction problem \n",
        "  * apply Bellman equation to obtain state values.\n",
        "* Use **_policy improvement_** for the control problem \n",
        " * obtain best policy by choosing maximal state-action values\n",
        "* Repeatedly iterating between policy evaluation and policy improvement is known as **_policy iteration_**. \n",
        "* The end result of policy iteration converges into the optimal policy. However, a faster alternative to policy iteration is **_value iteration_**.  \n",
        " * Instead of waiting for policy iteration to converge, we obtain the optimal value function (based on an arbitrary initial policy) by repeatedly updating values until they converge.\n",
        " * Subsequently, obtain the optimal policy (based on the optimal value function) in a single step. \n",
        "* Though the two approaches differ in levels of granularity (w.r.t evaluation/improvement), we term such approaches under the umbrella of **_generalised policy iteration_**, i.e. the repeated iterations of updating values (evaluation), and then updating the policy (improvement), regardless of granularity. \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4rYWkOHuvw"
      },
      "source": [
        "![policyiteration.png](data:image/png;base64,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)\n",
        "\n",
        "Fig 3. Depiction of Policy Iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoO-BdbhR6GM"
      },
      "source": [
        "## Policy Evaluation\n",
        "* What is the _value_ of a given policy?\n",
        " * Input: $\\pi(a|s)$\n",
        " * Output: $V_{\\pi}(s)$ or $Q_{\\pi}(s,a)$\n",
        "* The higher the values the better the policy.\n",
        "\n",
        "---\n",
        "* As a reminder, the Bellman equation for Policy Evaluation is:\n",
        "$$V_{\\pi}(s) = \\sum_{a} \\pi(a|s) \\sum_{s'} \\sum_{r} p(s',r|s,a)\\bigl(r+\\gamma V_{\\pi}(s')\\bigr)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1J_EUBdSFvP"
      },
      "source": [
        "### environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbxADS8hIJrA"
      },
      "source": [
        "class GridWorld:\n",
        "  def __init__(self,rows=3,cols=4,start_position=(2,0),walls=[(1,1)]):\n",
        "    '''pass in wall as a list'''\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "\n",
        "    # create state space\n",
        "    self.StateSpace = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    for wall in walls: self.StateSpace.remove(wall) #set walls\n",
        "    \n",
        "    # define action space\n",
        "    self.ActionSpace = ('U','D','L','R')\n",
        "    \n",
        "    # initialise states\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "\n",
        "    # define rewards\n",
        "    self.Rewards = {(0,3):1,(1,3):-1}\n",
        "\n",
        "    # initialise state values \n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    # initialise random policy\n",
        "    self.Policy = {s:{np.random.choice(['U','D','L','R']):1} for s in self.StateSpace}\n",
        "    for terminal_states in self.Rewards: self.Policy.pop(terminal_states, None)\n",
        "\n",
        "    #for visualisation\n",
        "    self.World = np.array([[' ' for _ in range(cols)] for _ in range(rows)])\n",
        "    for wall in walls: self.World[wall[0],wall[1]] = 'X'\n",
        "    for r in self.Rewards.keys():\n",
        "      if self.Rewards[r] > 0:\n",
        "        self.World[r[0],r[1]] = '+'\n",
        "      elif self.Rewards[r] < 0:\n",
        "        self.World[r[0],r[1]] = '-'\n",
        "   \n",
        "  def current_state(self):\n",
        "    return self.CurrentState\n",
        "\n",
        "  def previous_state(self):\n",
        "    return self.PreviousState\n",
        "\n",
        "  def get_all_states(self):\n",
        "    return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "\n",
        "  def get_next_state(self,state,action):\n",
        "    next_state = list(state)\n",
        "    if action == 'U':\n",
        "      next_state[0] -= 1\n",
        "    elif action == 'D':\n",
        "      next_state[0] += 1\n",
        "    elif action == 'L':\n",
        "      next_state[1] -= 1\n",
        "    elif action == 'R':\n",
        "      next_state[1] += 1\n",
        "    \n",
        "    if tuple(next_state) in self.StateSpace:\n",
        "      return tuple(next_state)\n",
        "    else:\n",
        "      return tuple(state)\n",
        "\n",
        "  def move(self,action,verbose=False):\n",
        "    # set previous state history first\n",
        "    self.PreviousState = self.CurrentState.copy()\n",
        "    \n",
        "    # perform move & update new state\n",
        "    self.CurrentState = self.get_next_state(self.PreviousState,action) #list(self.CurrentState)\n",
        "    \n",
        "    #print move\n",
        "    if verbose: print('Agent moved from %s to %s' % (self.PreviousState,self.CurrentState))\n",
        "    \n",
        "    # return reward\n",
        "    if self.CurrentState in self.Rewards.keys():\n",
        "      return self.Rewards[self.CurrentState] #return defined rewards\n",
        "    else:\n",
        "      return 0\n",
        "  \n",
        "  def game_over(self):\n",
        "    return self.CurrentState in self.Rewards.keys()\n",
        "\n",
        "  def is_terminal(self,state):\n",
        "    return state in self.Rewards.keys()\n",
        "\n",
        "  def visualise_world(self):\n",
        "    world = self.World.copy()\n",
        "    r,c = self.CurrentState\n",
        "    if self.CurrentState == self.PreviousState:\n",
        "      world[r,c] = '*'\n",
        "    else:\n",
        "      world[r,c] = 'o'\n",
        "    for r in world: \n",
        "      #print('-'+'--' * len(r))\n",
        "      print('|'+'%s|' * len(r) %tuple(r))\n",
        "\n",
        "  def set_policy(self,policy_dict):\n",
        "    self.Policy = policy_dict\n",
        "  \n",
        "  def set_state_values(self,values_dict):\n",
        "    self.StateValues = values_dict\n",
        "\n",
        "  def set_rewards(self,rewards_dict):\n",
        "    self.Rewards = rewards_dict\n",
        "\n",
        "  def set_transition_proba(self,transition_dict):\n",
        "    self.TransitionProb = transition_dict\n",
        "\n",
        "  def set_action_reward(self,actionreward_dict):\n",
        "    self.ActionReward = actionreward_dict\n",
        "\n",
        "  def visualise_values(self):\n",
        "    values = np.zeros((self.rows,self.cols))\n",
        "    for state in self.StateValues.keys():\n",
        "      r,c = state\n",
        "      values[r,c] = self.StateValues[state]\n",
        "    for rows in values:\n",
        "      print('|',end=\"\")\n",
        "      for c in rows:\n",
        "        if c >= 0:\n",
        "          print(' %.2f|' % c, end=\"\")\n",
        "        else:\n",
        "          print('%.2f|' % c, end=\"\")\n",
        "      print('\\n',end=\"\")\n",
        "  \n",
        "  def visualise_policy(self):\n",
        "    polmap = self.World.copy() #np.array([[' ' for _ in range(self.cols)] for _ in range(rows)])\n",
        "    for state in self.Policy:\n",
        "      r,c = state\n",
        "      action = list(self.Policy[state].keys())[0]\n",
        "      if action == 'U':\n",
        "        polmap[r,c] = '^'\n",
        "      elif action == 'D':\n",
        "        polmap[r,c] = 'v'\n",
        "      elif action == 'L':\n",
        "        polmap[r,c] = '<'\n",
        "      elif action == 'R':\n",
        "        polmap[r,c] = '>'\n",
        "    for p in polmap: print('|'+'%s|' * len(p) %tuple(p))\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeW0A007d508"
      },
      "source": [
        "### solving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_zuPE5dtI7c",
        "outputId": "2e143e97-bce3-445e-c19f-ce1f54d3a67f"
      },
      "source": [
        "## DEFINE TRANSITIONS & POLICY\n",
        "# constants\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "\n",
        "# initialise gridworld\n",
        "grid = GridWorld()\n",
        "\n",
        "# generate transition probabilities\n",
        "transition_dict = {}\n",
        "actionreward_dict = {}\n",
        "for r in range(grid.rows):\n",
        "  for c in range(grid.cols):\n",
        "    state = (r,c)\n",
        "    if not grid.is_terminal(state):\n",
        "      for action in grid.ActionSpace:\n",
        "        next_state = grid.get_next_state(state,action)\n",
        "        if state != next_state:\n",
        "          transition_dict[(state,action,next_state)] = 1\n",
        "        #if next_state in grid.Rewards:\n",
        "          #actionreward_dict[(state,action,next_state)] = grid.Rewards[next_state]\n",
        "\n",
        "grid.set_transition_proba(transition_dict)\n",
        "grid.set_action_reward(actionreward_dict)\n",
        "\n",
        "# set a fixed policy\n",
        "set_policy = {(0, 0): {'R':1},\n",
        "              (0, 1): {'R':1},\n",
        "              (0, 2): {'R':1},\n",
        "              (1, 0): {'U':1},\n",
        "              (1, 2): {'U':1},\n",
        "              (2, 0): {'U':1},\n",
        "              (2, 1): {'R':1},\n",
        "              (2, 2): {'U':1},\n",
        "              (2, 3): {'L':1}}\n",
        "\n",
        "grid.set_policy(set_policy)\n",
        "print('Set Policy')\n",
        "grid.visualise_policy()\n",
        "print('\\n\\n')\n",
        "\n",
        "# POLICY EVALUATION\n",
        "# repeat until convergence\n",
        "iter = 0\n",
        "while True:\n",
        "  biggest_change = 0\n",
        "\n",
        "  for state in grid.StateSpace: #state = list(a.StateValues.keys())[0]\n",
        "    if not grid.is_terminal(state): #if it is not a terminal state\n",
        "      old_v = grid.StateValues[state]\n",
        "      new_v = 0 #accumulate this\n",
        "      \n",
        "      for action in grid.ActionSpace:\n",
        "        for next_state in grid.StateSpace:\n",
        "\n",
        "          #action probability is deterministic, pi(a|s)\n",
        "          action_prob = grid.Policy[state].get(action,0)\n",
        "          #action_prob = 1 if list(grid.Policy[state].keys())[0] == action else 0\n",
        "\n",
        "          # get transition probabilities, p(s'|s,a)\n",
        "          transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "\n",
        "          # reward is a function of (s,a,s'), 0 if not specified\n",
        "          curr_reward = grid.Rewards.get(next_state,0)\n",
        "          #curr_reward = grid.ActionReward.get((state,action,next_state),0)\n",
        "\n",
        "          \n",
        "          # sum\n",
        "          new_v += action_prob * transition_prob * (curr_reward  + GAMMA * grid.StateValues[next_state])\n",
        "          #if action_prob: print('state: %s, action: %s, next_state: %s, V[s]: %.2f' % (state,action,next_state,new_v))\n",
        "\n",
        "      # after done getting new value, update value table\n",
        "      biggest_change = max(biggest_change,np.abs(new_v - old_v))\n",
        "      grid.StateValues[state] = new_v\n",
        "      \n",
        "\n",
        "  print('iteration: %d, biggest change: %.2f' % (iter,biggest_change))\n",
        "  grid.visualise_values()\n",
        "  iter += 1\n",
        "\n",
        "  print('\\n\\n')\n",
        "\n",
        "  if biggest_change < CONVERGENCE_LIMIT:\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set Policy\n",
            "|>|>|>|+|\n",
            "|^|X|^|-|\n",
            "|^|>|^|<|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 0, biggest change: 1.00\n",
            "| 0.00| 0.00| 1.00| 0.00|\n",
            "| 0.00| 0.00| 0.90| 0.00|\n",
            "| 0.00| 0.00| 0.81| 0.73|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 1, biggest change: 0.90\n",
            "| 0.00| 0.90| 1.00| 0.00|\n",
            "| 0.00| 0.00| 0.90| 0.00|\n",
            "| 0.00| 0.73| 0.81| 0.73|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 2, biggest change: 0.81\n",
            "| 0.81| 0.90| 1.00| 0.00|\n",
            "| 0.73| 0.00| 0.90| 0.00|\n",
            "| 0.66| 0.73| 0.81| 0.73|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 3, biggest change: 0.00\n",
            "| 0.81| 0.90| 1.00| 0.00|\n",
            "| 0.73| 0.00| 0.90| 0.00|\n",
            "| 0.66| 0.73| 0.81| 0.73|\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT9oLJhvrynj"
      },
      "source": [
        "Note to self: changes don't match with the video because of the order of the `StateSpace` that is explored every iteration, but they will eventually converge onto the same values. \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpBYK9sTPpsA",
        "outputId": "bd063ff9-7de0-4b73-f4a0-a3ca9e8f97b6"
      },
      "source": [
        "## WINDY GRIDWORLD - CHANCE TRANSITION PROBABILITY\n",
        "# constants\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "STEP_COST = -.01\n",
        "\n",
        "# initialise gridworld\n",
        "grid = GridWorld()\n",
        "\n",
        "# generate transition probabilities\n",
        "transition_dict = {}\n",
        "#actionreward_dict = {}\n",
        "for r in range(grid.rows):\n",
        "  for c in range(grid.cols):\n",
        "    state = (r,c)\n",
        "    if not grid.is_terminal(state):\n",
        "      for action in grid.ActionSpace:\n",
        "        next_state = grid.get_next_state(state,action)\n",
        "        #if state != next_state:\n",
        "        transition_dict[(state,action,next_state)] = 1\n",
        "        #if next_state in grid.Rewards:\n",
        "          #actionreward_dict[(state,action,next_state)] = grid.Rewards[next_state]\n",
        "\n",
        "windy_cells = {(1,2):{'action':'U',\n",
        "                      'trans':{(0,2):0.5,\n",
        "                               (1,3):0.5}}}\n",
        "for state in windy_cells:\n",
        "  action = windy_cells[state]['action']\n",
        "  for next_state in windy_cells[state]['trans']:\n",
        "    transition_dict[(state,action,next_state)] = windy_cells[state]['trans'][next_state]\n",
        "\n",
        "grid.set_transition_proba(transition_dict)\n",
        "#grid.set_action_reward(actionreward_dict)\n",
        "\n",
        "# set a fixed policy\n",
        "set_policy = {(0, 0): {'R':1},\n",
        "              (0, 1): {'R':1},\n",
        "              (0, 2): {'R':1},\n",
        "              (1, 0): {'U':1},\n",
        "              (1, 2): {'U':1},\n",
        "              (2, 0): {'U':0.5,'R':0.5},\n",
        "              (2, 1): {'R':1},\n",
        "              (2, 2): {'U':1},\n",
        "              (2, 3): {'L':1}}\n",
        "\n",
        "grid.set_policy(set_policy)\n",
        "print('Set Policy')\n",
        "grid.visualise_policy()\n",
        "print('\\n\\n')\n",
        "\n",
        "# POLICY EVALUATION\n",
        "# repeat until convergence\n",
        "iter = 0\n",
        "while True:\n",
        "  biggest_change = 0\n",
        "\n",
        "  for state in grid.StateSpace: #state = list(a.StateValues.keys())[0]\n",
        "    if not grid.is_terminal(state): #if it is not a terminal state\n",
        "      old_v = grid.StateValues[state]\n",
        "      new_v = 0 #accumulate this\n",
        "      \n",
        "      for action in grid.ActionSpace:\n",
        "        for next_state in grid.StateSpace:\n",
        "\n",
        "          #action probability is deterministic, pi(a|s)\n",
        "          action_prob = grid.Policy[state].get(action,0)\n",
        "          #action_prob = 1 if grid.Policy[state] == action else 0\n",
        "\n",
        "          # get transition probabilities, p(s'|s,a)\n",
        "          transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "\n",
        "          # reward is a function of (s,a,s'), 0 if not specified\n",
        "          curr_reward = grid.Rewards.get(next_state,0)\n",
        "          #curr_reward = grid.ActionReward.get((state,action,next_state),0)\n",
        "\n",
        "          \n",
        "          # sum\n",
        "          new_v += action_prob * transition_prob * (curr_reward  + GAMMA * grid.StateValues[next_state])\n",
        "          #if action_prob: print('state: %s, action: %s, next_state: %s, V[s]: %.2f' % (state,action,next_state,new_v))\n",
        "\n",
        "      # after done getting new value, update value table\n",
        "      biggest_change = max(biggest_change,np.abs(new_v - old_v))\n",
        "      grid.StateValues[state] = new_v\n",
        "      \n",
        "\n",
        "  print('iteration: %d, biggest change: %.2f' % (iter,biggest_change))\n",
        "  grid.visualise_values()\n",
        "  iter += 1\n",
        "\n",
        "  print('\\n\\n')\n",
        "\n",
        "  if biggest_change < CONVERGENCE_LIMIT:\n",
        "    break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set Policy\n",
            "|>|>|>|+|\n",
            "|^|X|^|-|\n",
            "|^|>|^|<|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 0, biggest change: 1.00\n",
            "| 0.00| 0.00| 1.00| 0.00|\n",
            "| 0.00| 0.00|-0.05| 0.00|\n",
            "| 0.00| 0.00|-0.04|-0.04|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 1, biggest change: 0.90\n",
            "| 0.00| 0.90| 1.00| 0.00|\n",
            "| 0.00| 0.00|-0.05| 0.00|\n",
            "| 0.00|-0.04|-0.04|-0.04|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 2, biggest change: 0.81\n",
            "| 0.81| 0.90| 1.00| 0.00|\n",
            "| 0.73| 0.00|-0.05| 0.00|\n",
            "| 0.31|-0.04|-0.04|-0.04|\n",
            "\n",
            "\n",
            "\n",
            "iteration: 3, biggest change: 0.00\n",
            "| 0.81| 0.90| 1.00| 0.00|\n",
            "| 0.73| 0.00|-0.05| 0.00|\n",
            "| 0.31|-0.04|-0.04|-0.04|\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlhlwDGedUfL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbSmlanTDMT6"
      },
      "source": [
        "## Policy Improvement\n",
        "\n",
        "* What is the _best policy_? In other words, given a policy, how do I find a better policy?\n",
        "* Assume that $\\pi$ is given, and we have found $V_{\\pi}(s)$ and $Q_{\\pi}(s,a)$. Suppose that we take an action _not_ prescribed by the policy, i.e. $a \\not= \\pi(s)$, but then follow $\\pi(s)$ thereafter. This can be calculated via Q-values.\n",
        " * if $Q_{\\pi}(s,a) > V_{\\pi}(s)$, then our return for the episode would be better than just following $\\pi$ the whole time. i.e. just one change can improve our expected return.\n",
        "* To find the best action, just look over the Q-table and take the max, i.e. we improve our policy greedily\n",
        "$$ a^{*} = \\arg \\max_{a} Q_{\\pi}(s,a) $$\n",
        "* If we perform this new action $a^{*}$ _every time_ we re-visit the same state, then we have a new policy, i.e. $\\pi'(s) \\not= \\pi(s)$ \n",
        "  * note that this is different from what was previously described, where it implies going back to the same policy $\\pi(s)$ after deviating _just once_.\n",
        "* **_Policy Improvement Theorem_**: New policy will be better as long as the new Q-value is larger than the previous state value, i.e.\n",
        "$$\\pi'(s) > \\pi(s) \\iff Q_{\\pi}(s,\\pi'(s)) \\geq V_{\\pi}(s)$$\n",
        "that is to say,\n",
        "$$ \\text{If} \\ Q_{\\pi}(s,\\pi'(s)) \\geq V_{\\pi}(s)$$\n",
        "$$ \\text{Then} \\ V_{\\pi'}(s) \\geq V_{\\pi}(s), \\forall s \\in \\mathcal{S} $$\n",
        " * If doing $a'$ _once_ is better than doing $a$ when visiting state $s$, then it is better to do so _every time_ we visit state $s$.\n",
        "* For all states except the terminal state,\n",
        "$$\\begin{aligned} \n",
        "\\pi'(s) &= \\arg \\max_{a} Q_{\\pi}(s,a)\n",
        "\\\\ &=  \\arg \\max_{a} \\sum_{s'} \\sum_{r} p(s',r|s,a)[r + \\gamma V_{\\pi}(s')], \\forall s \\in \\mathcal{S}, s \\not= S^T\n",
        "\\end{aligned}$$\n",
        "* Banach fixed point theorem implies that this procedure converges towards optimal policy, because policy will never get worse.\n",
        "* Note that while optimal values are unique, optimal policies are not necessarily so. Thus, to prevent an infinite loop of policy evaluation - policy improvement, we can stop once the values are stable (and will also be certain of obtaining at least 1 optimal policy)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEoUiAYzdbO2"
      },
      "source": [
        "### environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WICDMCeqpXaU"
      },
      "source": [
        "class GridWorld2:\n",
        "  def __init__(self,rows=3,cols=4,start_position=(2,0),walls=[(1,1)],rewards_dict={(0,3):1,(1,3):-1},step_cost=0):\n",
        "    '''pass in wall as a list'''\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "\n",
        "    # create state space\n",
        "    self.StateSpace = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    for wall in walls: self.StateSpace.remove(wall) #set walls\n",
        "    \n",
        "    # define action space\n",
        "    self.ActionSpace = ('U','D','L','R')\n",
        "    \n",
        "    # initialise states\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "\n",
        "    # define rewards\n",
        "    self.Rewards = rewards_dict\n",
        "    self.TerminalStates = list(self.Rewards.keys())\n",
        "\n",
        "    # define step cost\n",
        "    self.StepCost = step_cost\n",
        "\n",
        "    # initialise state values \n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    # define transition probabilities\n",
        "    self.TransitionProb = {}\n",
        "    for r in range(self.rows):\n",
        "      for c in range(self.cols):\n",
        "        state = (r,c)\n",
        "        if state not in self.TerminalStates:\n",
        "          for action in self.ActionSpace:\n",
        "            #move\n",
        "            next_state = list(state)\n",
        "            if action == 'U':\n",
        "              next_state[0] -= 1\n",
        "            elif action == 'D':\n",
        "              next_state[0] += 1\n",
        "            elif action == 'L':\n",
        "              next_state[1] -= 1\n",
        "            elif action == 'R':\n",
        "              next_state[1] += 1\n",
        "            next_state = tuple(next_state)\n",
        "\n",
        "            #check if valid\n",
        "            if next_state in self.StateSpace:\n",
        "              next_state_actual = next_state\n",
        "            else:\n",
        "              next_state_actual = state\n",
        "            \n",
        "            #assign transition probability\n",
        "            self.TransitionProb[(state,action,next_state_actual)] = 1\n",
        "\n",
        "    # initialise random policy\n",
        "    self.Policy = {s:{np.random.choice(['U','D','L','R']):1} for s in self.StateSpace}\n",
        "    for terminal_states in self.TerminalStates: self.Policy.pop(terminal_states, None)\n",
        "\n",
        "    #for visualisation\n",
        "    self.World = np.array([[' ' for _ in range(cols)] for _ in range(rows)])\n",
        "    for wall in walls: self.World[wall[0],wall[1]] = '#'\n",
        "    for r in self.Rewards.keys():\n",
        "      if self.Rewards[r] > 0:\n",
        "        self.World[r[0],r[1]] = '+'\n",
        "      elif self.Rewards[r] < 0:\n",
        "        self.World[r[0],r[1]] = '-'\n",
        "    \n",
        "  #set\n",
        "  def set_policy(self,policy_dict):\n",
        "    self.Policy = policy_dict\n",
        "  \n",
        "  def set_state_values(self,values_dict):\n",
        "    self.StateValues = values_dict\n",
        "\n",
        "  def set_transition_proba(self,transition_dict):\n",
        "    self.TransitionProb = transition_dict\n",
        "\n",
        "  \n",
        "  #gets\n",
        "  def get_all_states(self):\n",
        "    return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "\n",
        "  def get_next_state(self,state,action):\n",
        "    next_state = list(state)\n",
        "    if action == 'U':\n",
        "      next_state[0] -= 1\n",
        "    elif action == 'D':\n",
        "      next_state[0] += 1\n",
        "    elif action == 'L':\n",
        "      next_state[1] -= 1\n",
        "    elif action == 'R':\n",
        "      next_state[1] += 1\n",
        "    \n",
        "    if tuple(next_state) in self.StateSpace:\n",
        "      return tuple(next_state)\n",
        "    else:\n",
        "      return tuple(state)\n",
        "\n",
        "  def get_reward(self,next_state):\n",
        "    return self.Rewards.get(next_state,self.StepCost)\n",
        "  \n",
        "  #utils\n",
        "  def move(self,action,verbose=False):\n",
        "    # set previous state history first\n",
        "    self.PreviousState = self.CurrentState.copy()\n",
        "    \n",
        "    # perform move & update new state\n",
        "    self.CurrentState = self.get_next_state(self.PreviousState,action) #list(self.CurrentState)\n",
        "    \n",
        "    #print move\n",
        "    if verbose: print('Agent moved from %s to %s' % (self.PreviousState,self.CurrentState))\n",
        "    \n",
        "    # return reward\n",
        "    if self.CurrentState in self.Rewards.keys():\n",
        "      return self.Rewards[self.CurrentState] #return defined rewards\n",
        "    else:\n",
        "      return 0\n",
        "  \n",
        "  def game_over(self):\n",
        "    return self.CurrentState in self.Rewards.keys()\n",
        "\n",
        "  def is_terminal(self,state):\n",
        "    return state in self.Rewards.keys()\n",
        "\n",
        "\n",
        "  #visualisers\n",
        "  def visualise_world(self):\n",
        "    world = self.World.copy()\n",
        "    r,c = self.CurrentState\n",
        "    if self.CurrentState == self.PreviousState:\n",
        "      world[r,c] = '*'\n",
        "    else:\n",
        "      world[r,c] = 'o'\n",
        "    for r in world: \n",
        "      #print('-'+'--' * len(r))\n",
        "      print('|'+'%s|' * len(r) %tuple(r))\n",
        "\n",
        "  def visualise_values(self):\n",
        "    values = np.zeros((self.rows,self.cols))\n",
        "    for state in self.StateValues.keys():\n",
        "      r,c = state\n",
        "      values[r,c] = self.StateValues[state]\n",
        "    for rows in values:\n",
        "      print('|',end=\"\")\n",
        "      for c in rows:\n",
        "        if c >= 0:\n",
        "          print(' %.2f|' % c, end=\"\")\n",
        "        else:\n",
        "          print('%.2f|' % c, end=\"\")\n",
        "      print('\\n',end=\"\")\n",
        "  \n",
        "  def visualise_policy(self):\n",
        "    polmap = self.World.copy() #np.array([[' ' for _ in range(self.cols)] for _ in range(rows)])\n",
        "    for state in self.Policy:\n",
        "      r,c = state\n",
        "      action = list(self.Policy[state].keys())[0]\n",
        "      if action == 'U':\n",
        "        polmap[r,c] = '^'\n",
        "      elif action == 'D':\n",
        "        polmap[r,c] = 'v'\n",
        "      elif action == 'L':\n",
        "        polmap[r,c] = '<'\n",
        "      elif action == 'R':\n",
        "        polmap[r,c] = '>'\n",
        "    for p in polmap: print('|'+'%s|' * len(p) %tuple(p))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m99YKNwvdmJc"
      },
      "source": [
        "### solving\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu_C-nPzPpdT",
        "outputId": "5e5de85a-7b9a-44b2-afa4-b7324e814fdf"
      },
      "source": [
        "## STANDARD GRIDWORLD\n",
        "# constants\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "\n",
        "eval_pass = 0\n",
        "iter_pass = 0\n",
        "\n",
        "# initialise gridworld\n",
        "#grid = GridWorld2(5,5,(4,0),walls = [(1,1),(2,1),(3,1)],rewards_dict={(0,0):-1,(4,4):1})\n",
        "grid = GridWorld2()\n",
        "\n",
        "print('initial policy')\n",
        "grid.visualise_policy()\n",
        "# print('\\ninitial values')\n",
        "# grid.visualise_values()\n",
        "print('\\n\\n')    \n",
        "\n",
        "# start Eval-Iter loop\n",
        "while True:\n",
        "  ## POLICY EVALUATION LOOP\n",
        "  while True:\n",
        "    biggest_change = 0\n",
        "    for state in grid.StateSpace: #state = list(a.StateValues.keys())[0]\n",
        "      if not grid.is_terminal(state): #if it is not a terminal state\n",
        "        old_v = grid.StateValues[state]\n",
        "        new_v = 0 #accumulate this\n",
        "        \n",
        "        for action in grid.ActionSpace:\n",
        "          for next_state in grid.StateSpace:\n",
        "\n",
        "            #action probability is deterministic, pi(a|s)\n",
        "            action_prob = grid.Policy[state].get(action,0)\n",
        "\n",
        "            # get transition probabilities, p(s'|s,a)\n",
        "            transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "\n",
        "            # reward is a function of (s,a,s'), 0 if not specified\n",
        "            curr_reward = grid.get_reward(next_state)\n",
        "            \n",
        "            # sum\n",
        "            new_v += action_prob * transition_prob * (curr_reward  + GAMMA * grid.StateValues[next_state])\n",
        "            \n",
        "        # after done getting new value, update value table\n",
        "        biggest_change = max(biggest_change,np.abs(new_v - old_v))\n",
        "        grid.StateValues[state] = new_v\n",
        "  \n",
        "    # evaluate current policy repeatedly until values have been propogated to all cells and converged\n",
        "    if biggest_change < CONVERGENCE_LIMIT:\n",
        "      eval_pass += 1\n",
        "      break\n",
        "\n",
        "  print('Evaluation loop %d done' % (eval_pass))\n",
        "  del state, action, next_state\n",
        "\n",
        "  ## POLICY ITERATION LOOP\n",
        "  is_policy_converged = True\n",
        "  #loop through every state that has a Policy\n",
        "  for state in grid.Policy: \n",
        "    action_old = max(grid.Policy[state], key=grid.Policy[state].get) #get the current assigned action (or best action if probabilistic)\n",
        "    action_new = None #init new action\n",
        "    best_value = float('-inf')\n",
        "    \n",
        "    #now loop through every possible action (up, down, left, right)\n",
        "    for action in grid.ActionSpace: \n",
        "      q = 0 #initialise Q-value of this action\n",
        "      for next_state in grid.StateSpace:\n",
        "        # get transition probabilities of next state, if action was performed\n",
        "        transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "        \n",
        "        #get reward of next state, if action was performed\n",
        "        curr_reward = grid.get_reward(next_state)\n",
        "        \n",
        "        #update q of this action\n",
        "        q += transition_prob * (curr_reward + GAMMA * grid.StateValues[next_state])\n",
        "      \n",
        "      #after q has been summed for all successor states, for this action,\n",
        "      if q > best_value:\n",
        "        best_value = q #update best_value if this action improved state value\n",
        "        action_new = action #record this action as the best action for now\n",
        "    \n",
        "    #after all actions have been looped through\n",
        "    grid.Policy[state] = {action_new : 1}\n",
        "\n",
        "    #change policy converged flag to False, so long as at least 1 action in the policy was updated.\n",
        "    if action_new != action_old: is_policy_converged = False\n",
        "  \n",
        "  #update number of times policy iteration has completed\n",
        "  iter_pass += 1\n",
        "  print('Iteration loop %d done' % (iter_pass))\n",
        "  \n",
        "  #after looping through all policies, if policies were updated, then break.\n",
        "  #If not, since all policies have been scanned through and updated, re-evaluate the new policy again.\n",
        "  if is_policy_converged:\n",
        "    print('Finished')\n",
        "    break\n",
        "    \n",
        "\n",
        "print('\\n\\n')\n",
        "print('final policy')  \n",
        "grid.visualise_policy()\n",
        "print('\\nfinal values')  \n",
        "grid.visualise_values()    \n",
        "\n",
        "#del grid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial policy\n",
            "|^|>|v|+|\n",
            "|<|#|^|-|\n",
            "|<|^|v|^|\n",
            "\n",
            "\n",
            "\n",
            "Evaluation loop 1 done\n",
            "Iteration loop 1 done\n",
            "Evaluation loop 2 done\n",
            "Iteration loop 2 done\n",
            "Evaluation loop 3 done\n",
            "Iteration loop 3 done\n",
            "Evaluation loop 4 done\n",
            "Iteration loop 4 done\n",
            "Evaluation loop 5 done\n",
            "Iteration loop 5 done\n",
            "Finished\n",
            "\n",
            "\n",
            "\n",
            "final policy\n",
            "|>|>|>|+|\n",
            "|^|#|^|-|\n",
            "|^|>|^|<|\n",
            "\n",
            "final values\n",
            "| 0.81| 0.90| 1.00| 0.00|\n",
            "| 0.73| 0.00| 0.90| 0.00|\n",
            "| 0.66| 0.73| 0.81| 0.73|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JikfepEkmCYR",
        "outputId": "8e1bb23a-6b00-4aa8-c85d-65e31343f763"
      },
      "source": [
        "## WINDY GRIDWORLD\n",
        "# constants\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "PENALTY = -.1 #also see how value changes for 0, -.2, -.4, -.5 & -2\n",
        "\n",
        "eval_pass = 0\n",
        "iter_pass = 0\n",
        "\n",
        "# initialise gridworld\n",
        "grid = GridWorld2(step_cost = PENALTY)\n",
        "\n",
        "print('initial policy')\n",
        "grid.visualise_policy()\n",
        "# print('\\ninitial values')\n",
        "# grid.visualise_values()\n",
        "print('\\n\\n')    \n",
        "\n",
        "# set windy cells\n",
        "transition_dict_ = grid.TransitionProb.copy()\n",
        "windy_cells = {(1,2):{'action':'U',\n",
        "                      'trans':{(0,2):0.5,\n",
        "                               (1,3):0.5}}}\n",
        "for state in windy_cells:\n",
        "  action = windy_cells[state]['action']\n",
        "  for next_state in windy_cells[state]['trans']:\n",
        "    transition_dict_[(state,action,next_state)] = windy_cells[state]['trans'][next_state]\n",
        "\n",
        "grid.set_transition_proba(transition_dict_)\n",
        "\n",
        "# start Eval-Iter loop\n",
        "while True:\n",
        "  ## POLICY EVALUATION LOOP\n",
        "  while True:\n",
        "    biggest_change = 0\n",
        "    for state in grid.StateSpace: #state = list(a.StateValues.keys())[0]\n",
        "      if not grid.is_terminal(state): #if it is not a terminal state\n",
        "        old_v = grid.StateValues[state]\n",
        "        new_v = 0 #accumulate this\n",
        "        \n",
        "        for action in grid.ActionSpace:\n",
        "          for next_state in grid.StateSpace:\n",
        "\n",
        "            #action probability is deterministic, pi(a|s)\n",
        "            action_prob = grid.Policy[state].get(action,0)\n",
        "\n",
        "            # get transition probabilities, p(s'|s,a)\n",
        "            transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "\n",
        "            # reward is a function of (s,a,s'), 0 if not specified\n",
        "            curr_reward = grid.get_reward(next_state)\n",
        "            \n",
        "            # sum\n",
        "            new_v += action_prob * transition_prob * (curr_reward  + GAMMA * grid.StateValues[next_state])\n",
        "            \n",
        "        # after done getting new value, update value table\n",
        "        biggest_change = max(biggest_change,np.abs(new_v - old_v))\n",
        "        grid.StateValues[state] = new_v\n",
        "  \n",
        "    # evaluate current policy repeatedly until values have been propogated to all cells and converged\n",
        "    if biggest_change < CONVERGENCE_LIMIT:\n",
        "      eval_pass += 1\n",
        "      break\n",
        "\n",
        "  print('Evaluation loop %d done' % (eval_pass))\n",
        "  del state, action, next_state\n",
        "\n",
        "  ## POLICY ITERATION LOOP\n",
        "  is_policy_converged = True\n",
        "  #loop through every state that has a Policy\n",
        "  for state in grid.Policy: \n",
        "    action_old = max(grid.Policy[state], key=grid.Policy[state].get) #get the current assigned action (or best action if probabilistic)\n",
        "    action_new = None #init new action\n",
        "    best_value = float('-inf')\n",
        "    \n",
        "    #now loop through every possible action (up, down, left, right)\n",
        "    for action in grid.ActionSpace: \n",
        "      q = 0 #initialise Q-value of this action\n",
        "      for next_state in grid.StateSpace:\n",
        "        # get transition probabilities of next state, if action was performed\n",
        "        transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "        \n",
        "        #get reward of next state, if action was performed\n",
        "        curr_reward = grid.get_reward(next_state)\n",
        "        \n",
        "        #update q of this action\n",
        "        q += transition_prob * (curr_reward + GAMMA * grid.StateValues[next_state])\n",
        "      \n",
        "      #after q has been summed for all successor states, for this action,\n",
        "      if q > best_value:\n",
        "        best_value = q #update best_value if this action improved state value\n",
        "        action_new = action #record this action as the best action for now\n",
        "    \n",
        "    #after all actions have been looped through\n",
        "    grid.Policy[state] = {action_new : 1}\n",
        "\n",
        "    #change policy converged flag to False, so long as at least 1 action in the policy was updated.\n",
        "    if action_new != action_old: is_policy_converged = False\n",
        "  \n",
        "  #update number of times policy iteration has completed\n",
        "  iter_pass += 1\n",
        "  print('Iteration loop %d done' % (iter_pass))\n",
        "  \n",
        "  #after looping through all policies, if policies were updated, then break.\n",
        "  #If not, since all policies have been scanned through and updated, re-evaluate the new policy again.\n",
        "  if is_policy_converged:\n",
        "    print('Finished')\n",
        "    break\n",
        "    \n",
        "\n",
        "print('\\n\\n')\n",
        "print('final policy')  \n",
        "grid.visualise_policy()\n",
        "print('\\nfinal values')  \n",
        "grid.visualise_values()    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial policy\n",
            "|<|v|^|+|\n",
            "|^|I|>|-|\n",
            "|v|^|v|>|\n",
            "\n",
            "\n",
            "\n",
            "Evaluation loop 1 done\n",
            "Iteration loop 1 done\n",
            "Evaluation loop 2 done\n",
            "Iteration loop 2 done\n",
            "Evaluation loop 3 done\n",
            "Iteration loop 3 done\n",
            "Evaluation loop 4 done\n",
            "Iteration loop 4 done\n",
            "Evaluation loop 5 done\n",
            "Iteration loop 5 done\n",
            "Evaluation loop 6 done\n",
            "Iteration loop 6 done\n",
            "Evaluation loop 7 done\n",
            "Iteration loop 7 done\n",
            "Evaluation loop 8 done\n",
            "Iteration loop 8 done\n",
            "Finished\n",
            "\n",
            "\n",
            "\n",
            "final policy\n",
            "|>|>|>|+|\n",
            "|^|I|v|-|\n",
            "|^|<|<|<|\n",
            "\n",
            "final values\n",
            "| 0.62| 0.80| 1.00| 0.00|\n",
            "| 0.46| 0.00|-0.04| 0.00|\n",
            "| 0.31| 0.18| 0.06|-0.04|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obySu4irdi-N"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qlbFLbBzT9A"
      },
      "source": [
        "\n",
        "## Value iteration\n",
        "* As can be seen from the previous section, policy iteration consists of 2 nested loops. This could take a long time to converge (if at all).\n",
        "* We can speed up the process by\n",
        " * Computing optimal state values by _repeatedly updating_ state values only, without regard for the action, i.e. evaluate each policy via\n",
        " $$ v_{k+1}(s) = \\max_{a} \\sum_{s'} \\sum_{r} p(s',r|s,a)[r + \\gamma v_{k}(s)] $$\n",
        " and whenever $v_{k+1}(s) = v_{k}(s)$, we must have found $v^{*}$\n",
        " * Proceeding to policy improvement from optimal state values.\n",
        " $$\\pi^{*}(s) = \\arg \\max_{a} Q_{\\pi}(s,a)$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X813r0YkmCWl",
        "outputId": "df090436-bd45-4916-b4b1-30f1f91bd379"
      },
      "source": [
        "## VALUE ITERATION\n",
        "# constants\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "PENALTY = 0\n",
        "\n",
        "eval_pass = 0\n",
        "iter_pass = 0\n",
        "\n",
        "# initialise gridworld\n",
        "#grid = GridWorld2(step_cost=PENALTY)\n",
        "#grid = GridWorld2(5,5,(4,0),walls = [(1,1),(2,1),(3,1)],rewards_dict={(0,0):-1,(4,4):1})\n",
        "grid = GridWorld2(5,5,(4,0),walls = [(1,1),(2,2),(3,1)],rewards_dict={(0,0):-1,(4,4):1})\n",
        "\n",
        "print('initial policy')\n",
        "grid.visualise_policy()\n",
        "# print('\\ninitial values')\n",
        "# grid.visualise_values()\n",
        "print('\\n')    \n",
        "\n",
        "# set windy cells\n",
        "transition_dict_ = grid.TransitionProb.copy()\n",
        "windy_cells = {(1,2):{'action':'U',\n",
        "                      'trans':{(0,2):0.5,\n",
        "                               (1,3):0.5}}}\n",
        "for state in windy_cells:\n",
        "  action = windy_cells[state]['action']\n",
        "  for next_state in windy_cells[state]['trans']:\n",
        "    transition_dict_[(state,action,next_state)] = windy_cells[state]['trans'][next_state]\n",
        "\n",
        "grid.set_transition_proba(transition_dict_)\n",
        "\n",
        "## VALUE ITERATION LOOP\n",
        "while True:\n",
        "  biggest_change = 0\n",
        "  for state in grid.StateSpace: #state = list(a.StateValues.keys())[0]\n",
        "    if not grid.is_terminal(state): #if it is not a terminal state\n",
        "      old_v = grid.StateValues[state]\n",
        "      new_v = float('-inf') #set lowest possible value for new_v\n",
        "      \n",
        "      ## find max value\n",
        "      #loop through all actions\n",
        "      for action in grid.ActionSpace:\n",
        "        v = 0\n",
        "        for next_state in grid.StateSpace:\n",
        "          # get transition probabilities, p(s'|s,a)\n",
        "          transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "\n",
        "          # reward is a function of (s,a,s'), 0 if not specified\n",
        "          curr_reward = grid.get_reward(next_state)\n",
        "\n",
        "          # sum across all possible V(s') in the current state\n",
        "          v += transition_prob * (curr_reward  + GAMMA * grid.StateValues[next_state])\n",
        "          \n",
        "        # take max new_v\n",
        "        if v > new_v:\n",
        "          new_v = v\n",
        "          \n",
        "      # after done getting new value, update value table\n",
        "      biggest_change = max(biggest_change,np.abs(new_v - old_v))\n",
        "      grid.StateValues[state] = new_v\n",
        "\n",
        "  # evaluate current policy repeatedly until values have been propogated to all cells and converged\n",
        "  if biggest_change < CONVERGENCE_LIMIT:\n",
        "    eval_pass += 1\n",
        "    break\n",
        "\n",
        "## Update Policy\n",
        "#loop through every state that has a Policy\n",
        "for state in grid.Policy: \n",
        "  action_new = None #init new action\n",
        "  best_value = float('-inf')\n",
        "  \n",
        "  #now loop through every possible action (up, down, left, right)\n",
        "  for action in grid.ActionSpace: \n",
        "    q = 0 #initialise Q-value of this action\n",
        "    for next_state in grid.StateSpace:\n",
        "      # get transition probabilities of next state, if action was performed\n",
        "      transition_prob = grid.TransitionProb.get((state,action,next_state),0)\n",
        "      \n",
        "      #get reward of next state, if action was performed\n",
        "      curr_reward = grid.get_reward(next_state)\n",
        "      \n",
        "      #update q of this action\n",
        "      q += transition_prob * (curr_reward + GAMMA * grid.StateValues[next_state])\n",
        "    \n",
        "    #after q has been summed for all successor states, for this action,\n",
        "    if q > best_value:\n",
        "      best_value = q #update best_value if this action improved state value\n",
        "      action_new = action #record this action as the best action for now\n",
        "  \n",
        "  #after all actions have been looped through\n",
        "  grid.Policy[state] = {action_new : 1}\n",
        "\n",
        "print('final policy')  \n",
        "grid.visualise_policy()\n",
        "print('\\nfinal values')  \n",
        "grid.visualise_values()   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial policy\n",
            "|-|<|v|<|>|\n",
            "|>|I|^|^|>|\n",
            "|v|<|I|>|v|\n",
            "|>|I|>|v|<|\n",
            "|<|v|v|v|+|\n",
            "\n",
            "\n",
            "final policy\n",
            "|-|>|v|v|v|\n",
            "|v|I|>|v|v|\n",
            "|v|<|I|v|v|\n",
            "|v|I|v|v|v|\n",
            "|>|>|>|>|+|\n",
            "\n",
            "final values\n",
            "| 0.00| 0.53| 0.59| 0.66| 0.73|\n",
            "| 0.53| 0.00| 0.66| 0.73| 0.81|\n",
            "| 0.59| 0.53| 0.00| 0.81| 0.90|\n",
            "| 0.66| 0.00| 0.81| 0.90| 1.00|\n",
            "| 0.73| 0.81| 0.90| 1.00| 0.00|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU7vz4rDh_QP"
      },
      "source": [
        "# **Monte-Carlo Methods**\n",
        "\n",
        "* MC methods directly sample episodes. We can used the experience sampled to learn when the environment dynamics are unknown (i.e. no knowledge of MDP required)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RjthkW1ltkr"
      },
      "source": [
        "## Monte Carlo Policy Evaluation\n",
        "\n",
        "* Given a policy $\\pi$, how can we find $V_{\\pi}(s)$ or $Q_{\\pi}(s,a)$ without knowing the environment dynamics, $p(s',r|s,a)$?\n",
        "* Play a bunch of episodes, collect $G$ samples, and average:\n",
        "$$V_{\\pi}(s) = \\Bbb{E}[G_{t}|S_{t} = s] \\approx \\frac{1}{N} \\sum_{i=1}^{N}G_{i,s}$$\n",
        "Where $G_{i,s}$ represents the $i$-th sample return from state $s$.\n",
        "\n",
        "--- \n",
        "\n",
        "**Issues to consider**\n",
        "* What is the value of a state _not_ visited by our policy? \n",
        " * If we keep a **_probabilistic policy, with non-zero probability for all actions_**, then it would not be an issue.\n",
        "* What if we encounter the same state more than once? Is the return the sum of rewards after the first visit, or after subsequent visits? We can either do:\n",
        " * **_First visit MC_**: only count the first visit\n",
        " * **_Every visit MC_**: count every visit\n",
        " * Both options converge to the same answer\n",
        "* What if policy results in an infinite cycle?\n",
        " * terminate episode after a max number of steps.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_S6u8ShUIv"
      },
      "source": [
        "### environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMbNtWdkmCQH"
      },
      "source": [
        "class GridWorld3:\n",
        "  def __init__(self,rows=3,cols=4,start_position=(2,0),walls=[(1,1)],rewards_dict={(0,3):1,(1,3):-1},step_cost=0):\n",
        "    '''pass in wall as a list'''\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "    \n",
        "\n",
        "    ## ENVIRONMENT MODEL\n",
        "    # create state space\n",
        "    self.StateSpace = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    self.Walls = walls\n",
        "    for wall in self.Walls: self.StateSpace.remove(wall) #set walls\n",
        "    \n",
        "    # define action space\n",
        "    self.ActionSpace = ('U','D','L','R')\n",
        "    \n",
        "    # define rewards\n",
        "    self.Rewards = rewards_dict\n",
        "    self.TerminalStates = list(self.Rewards.keys())\n",
        "\n",
        "    # define step cost\n",
        "    self.StepCost = step_cost\n",
        "\n",
        "    # define transition probabilities\n",
        "    self.TransitionProb = {}\n",
        "    for r in range(self.rows):\n",
        "      for c in range(self.cols):\n",
        "        state = (r,c)\n",
        "        if state not in self.TerminalStates:\n",
        "          for action in self.ActionSpace:\n",
        "            #move\n",
        "            next_state = list(state)\n",
        "            if action == 'U':\n",
        "              next_state[0] -= 1\n",
        "            elif action == 'D':\n",
        "              next_state[0] += 1\n",
        "            elif action == 'L':\n",
        "              next_state[1] -= 1\n",
        "            elif action == 'R':\n",
        "              next_state[1] += 1\n",
        "            next_state = tuple(next_state)\n",
        "\n",
        "            #check if valid\n",
        "            if next_state in self.StateSpace:\n",
        "              next_state_actual = next_state\n",
        "            else:\n",
        "              next_state_actual = state\n",
        "            \n",
        "            #assign transition probability\n",
        "            self.TransitionProb[(state,action,next_state_actual)] = 1\n",
        "\n",
        "    #for visualisation\n",
        "    self.World = np.array([[' ' for _ in range(cols)] for _ in range(rows)])\n",
        "    for wall in walls: self.World[wall[0],wall[1]] = '#'\n",
        "    for r in self.Rewards.keys():\n",
        "      if self.Rewards[r] > 0:\n",
        "        self.World[r[0],r[1]] = '+'\n",
        "      elif self.Rewards[r] < 0:\n",
        "        self.World[r[0],r[1]] = '-'\n",
        "\n",
        "    ##--------------------------------------------------------------------##\n",
        "\n",
        "    ## INITIALISED VALUES FOR LEARNING\n",
        "    # initialise states\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "   \n",
        "    # initialise state values \n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    # initialise random policy (here we assume NO KNOWLEDGE of the environment)\n",
        "    self.Policy = {s:{np.random.choice(['U','D','L','R']):1} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    # initialise returns\n",
        "    self.Returns = {s:[] for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    ##--------------------------------------------------------------------##\n",
        "\n",
        "  #set\n",
        "  def set_policy(self,policy_dict):\n",
        "    self.Policy = policy_dict\n",
        "  \n",
        "  def set_state_values(self,values_dict):\n",
        "    self.StateValues = values_dict\n",
        "\n",
        "  def set_transition_proba(self,transition_dict):\n",
        "    self.TransitionProb = transition_dict\n",
        "\n",
        "  def set_fixed_policy(self):\n",
        "    # set a fixed policy\n",
        "    self.Policy = {(0, 0): {'R':1},\n",
        "                  (0, 1): {'R':1},\n",
        "                  (0, 2): {'R':1},\n",
        "                  (1, 0): {'U':1},\n",
        "                  (1, 2): {'U':1},\n",
        "                  (2, 0): {'U':1},\n",
        "                  (2, 1): {'R':1},\n",
        "                  (2, 2): {'U':1},\n",
        "                  (2, 3): {'L':1}}\n",
        "  \n",
        "  def set_random_policy(self):\n",
        "    self.Policy = {s:{np.random.choice(['U','D','L','R']):1} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  #gets\n",
        "  def get_all_states(self):\n",
        "    return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "  \n",
        "  def get_valid_states(self):\n",
        "    available_states = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    for wall in self.Walls: available_states.remove(wall) #set walls\n",
        "    for term in self.TerminalStates: available_states.remove(term) #set walls\n",
        "    return available_states\n",
        "\n",
        "  def get_next_state(self,state,action):\n",
        "    next_state = list(state)\n",
        "    if action == 'U':\n",
        "      next_state[0] -= 1\n",
        "    elif action == 'D':\n",
        "      next_state[0] += 1\n",
        "    elif action == 'L':\n",
        "      next_state[1] -= 1\n",
        "    elif action == 'R':\n",
        "      next_state[1] += 1\n",
        "    \n",
        "    if tuple(next_state) in self.StateSpace:\n",
        "      return tuple(next_state)\n",
        "    else:\n",
        "      return tuple(state)\n",
        "\n",
        "  def get_reward(self,next_state):\n",
        "    return self.Rewards.get(next_state,self.StepCost)\n",
        "  \n",
        "  #utils\n",
        "  def move(self,action,verbose=False):\n",
        "    # set previous state history first\n",
        "    self.PreviousState = self.CurrentState\n",
        "    \n",
        "    # perform move & update new state\n",
        "    self.CurrentState = self.get_next_state(self.PreviousState,action) #list(self.CurrentState)\n",
        "    \n",
        "    #print move\n",
        "    if verbose: print('Agent moved from %s to %s' % (self.PreviousState,self.CurrentState))\n",
        "    \n",
        "    # return reward\n",
        "    return self.Rewards.get(self.CurrentState,self.StepCost) #return defined rewards\n",
        "\n",
        "  def game_over(self):\n",
        "    return self.CurrentState in self.TerminalStates\n",
        "\n",
        "  def is_terminal(self,state):\n",
        "    return state in self.TerminalStates\n",
        "  \n",
        "  #resets\n",
        "  def reset_location(self,start_position=(2,0)):\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "\n",
        "  def reset_values(self):\n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  #visualisers\n",
        "  def visualise_world(self):\n",
        "    world = self.World.copy()\n",
        "    r,c = self.CurrentState\n",
        "    if self.CurrentState == self.PreviousState:\n",
        "      world[r,c] = '*'\n",
        "    else:\n",
        "      world[r,c] = 'o'\n",
        "    for r in world: \n",
        "      #print('-'+'--' * len(r))\n",
        "      print('|'+'%s|' * len(r) %tuple(r))\n",
        "\n",
        "  def visualise_values(self):\n",
        "    values = np.zeros((self.rows,self.cols))\n",
        "    for state in self.StateValues.keys():\n",
        "      r,c = state\n",
        "      values[r,c] = self.StateValues[state]\n",
        "    for rows in values:\n",
        "      print('|',end=\"\")\n",
        "      for c in rows:\n",
        "        if c >= 0:\n",
        "          print(' %.2f|' % c, end=\"\")\n",
        "        else:\n",
        "          print('%.2f|' % c, end=\"\")\n",
        "      print('\\n',end=\"\")\n",
        "  \n",
        "  def visualise_policy(self):\n",
        "    polmap = self.World.copy() #np.array([[' ' for _ in range(self.cols)] for _ in range(rows)])\n",
        "    for state in self.Policy:\n",
        "      r,c = state\n",
        "      action = list(self.Policy[state].keys())[0]\n",
        "      if action == 'U':\n",
        "        polmap[r,c] = '^'\n",
        "      elif action == 'D':\n",
        "        polmap[r,c] = 'v'\n",
        "      elif action == 'L':\n",
        "        polmap[r,c] = '<'\n",
        "      elif action == 'R':\n",
        "        polmap[r,c] = '>'\n",
        "    for p in polmap: print('|'+'%s|' * len(p) %tuple(p))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CprD3tVhhWDw"
      },
      "source": [
        "### solving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11H_wx-kh-z7",
        "outputId": "954257a9-ac06-4e83-fbf9-3c62b0220dff"
      },
      "source": [
        "## MONTE CARLO PREDICTION PROBLEM\n",
        "## setup\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "MAX_EP_STEPS = 20\n",
        "\n",
        "## initialise environment\n",
        "grid = GridWorld3()\n",
        "#grid.set_fixed_policy()\n",
        "#grid.set_random_policy()\n",
        "\n",
        "policy_dict = {\n",
        "    (2, 0): {'U':1},\n",
        "    (1, 0): {'U':1},\n",
        "    (0, 0): {'R':1},\n",
        "    (0, 1): {'R':1},\n",
        "    (0, 2): {'R':1},\n",
        "    (1, 2): {'R':1},\n",
        "    (2, 1): {'R':1},\n",
        "    (2, 2): {'R':1},\n",
        "    (2, 3): {'U':1},\n",
        "  }\n",
        "grid.set_policy(policy_dict)\n",
        "\n",
        "\n",
        "available_states = grid.get_valid_states() #shortcut to define available states\n",
        "\n",
        "\n",
        "## interact until convergence\n",
        "#while True:\n",
        "for _ in range(100):\n",
        "#for ss in available_states:\n",
        "\n",
        "  # SETUP\n",
        "  s_idx = np.random.choice(len(available_states))\n",
        "  grid.reset_location(available_states[s_idx]) #randomise start locations\n",
        "\n",
        "  ## START PLAYING EPISODE\n",
        "  # initialise lists to keep track of agent history\n",
        "  state_history = [grid.CurrentState]\n",
        "  reward_history = [0]\n",
        "\n",
        "  # play up to MAX_EP_STEPS steps\n",
        "  for i in range(MAX_EP_STEPS):\n",
        "    if grid.game_over():\n",
        "      #print(episode done)\n",
        "      break\n",
        "  \n",
        "    #get action\n",
        "    action = max(grid.Policy[grid.CurrentState], key=grid.Policy[grid.CurrentState].get)\n",
        "\n",
        "    #get reward\n",
        "    reward = grid.move(action) #note that this method implicitly updates grid.CurrenState\n",
        "\n",
        "    #update state and reward history\n",
        "    state_history.append(grid.CurrentState)\n",
        "    reward_history.append(reward)\n",
        "    \n",
        "    ## print loop terminated status if max loops reached\n",
        "    #if i == MAX_EP_STEPS: print('episode terminated')\n",
        "\n",
        "\n",
        "  ## CALCULATE RETURNS\n",
        "  old_V = grid.StateValues.copy()\n",
        "  returns = {}\n",
        "  G = 0\n",
        "  for t in range(len(state_history)-2,-1,-1): #reverse order\n",
        "    sh = state_history[t]\n",
        "    rh = reward_history[t+1]\n",
        "\n",
        "    # sum returns\n",
        "    G = rh + GAMMA * G\n",
        "\n",
        "    if sh not in state_history[:t]: #check for first-visit \n",
        "      if sh not in returns: returns[sh] = [] #create empty list if new key\n",
        "      returns[sh].append(G)\n",
        "      grid.StateValues[sh] = np.mean(returns[sh])\n",
        "    \n",
        "\n",
        "\n",
        "  # #check to see if each grid values are updated\n",
        "  # for state in grid.StateValues:\n",
        "  #   if np.abs(grid.StateValues[state] - old_V[state]) < CONVERGENCE_LIMIT:\n",
        "  #     break_flag = True\n",
        "  #   else:\n",
        "  #     break_flag = False\n",
        "\n",
        "  # if break_flag == True:\n",
        "  #   break\n",
        "\n",
        "\n",
        "grid.visualise_policy()\n",
        "print('\\n')\n",
        "grid.visualise_values()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|>|>|>|+|\n",
            "|^|#|>|-|\n",
            "|^|>|>|^|\n",
            "| 0.81| 0.90| 1.00| 0.00|\n",
            "| 0.73| 0.00|-1.00| 0.00|\n",
            "| 0.66|-0.81|-0.90|-1.00|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMFpRvb-ShtF"
      },
      "source": [
        "## Monte-Carlo Policy Improvement\n",
        "\n",
        "* Now that we can evaluate policy $\\pi$, and gotten an initial estimate of $V_{\\pi}(s)$, how can we improve it?\n",
        "* Iteration usually involves taking the argmax of the expected value of the next state $s'$, i.e.\n",
        "$$\\pi^{*}(s) = \\arg \\max_{a} \\sum_{s',r} p(s',r|s,a) [r + \\gamma V_{\\pi}(s')]$$\n",
        "* However, generally, we do not know the transition dynamics $p(s',r|s,a)$ of the environment. But note that \n",
        "$$ \\sum_{s',r} p(s',r|s,a) [r + \\gamma V_{\\pi}(s')] = Q_{\\pi}(s,a)$$\n",
        "Therefore, we modify out previous Evaluation step slightly, to keep track of estimates of $Q_{\\pi}(s,a)$ instead of $V_{\\pi}(s)$\n",
        "  * recall again that $V_{\\pi}(s) = \\sum_{a} \\pi(a|s) Q_{\\pi}(s,a)$\n",
        "* Then, we obtain policy improvement by:\n",
        "$$\\pi^{*}(s) = \\arg \\max_{a} Q_{\\pi}(s,a)$$\n",
        "* However, now we have to keep track of even more samples than before, since $Q$ has $|S| \\times |A|$ values. To ease this load, we use a strategy akin to Value Iteration, which is:\n",
        " * Play one episode, update $Q$ with the returns sampled\n",
        " * Immediately update $\\pi$ using the latest $Q$\n",
        "* However, if we always start at the same state, we can never obtain value estimates for other states. Thus we implement **_exploring starts_**, which is to randomly start each interaction episode at a different state.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rW2WK4qhvSl"
      },
      "source": [
        "### environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEAFu1PqV5Dg"
      },
      "source": [
        "class GridWorld4:\n",
        "  def __init__(self,rows=3,cols=4,start_position=(2,0),walls=[(1,1)],rewards_dict={(0,3):1,(1,3):-1},step_cost=0):\n",
        "    '''pass in wall as a list'''\n",
        "        \n",
        "    ## ENVIRONMENT MODEL\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "\n",
        "    # create state space\n",
        "    self.StateSpace = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    self.Walls = walls\n",
        "    for wall in self.Walls: self.StateSpace.remove(wall) #set walls\n",
        "    \n",
        "    # define action space\n",
        "    self.ActionSpace = ('U','D','L','R')\n",
        "    \n",
        "    # define rewards\n",
        "    self.Rewards = rewards_dict\n",
        "    self.TerminalStates = list(self.Rewards.keys())\n",
        "\n",
        "    # define step cost\n",
        "    self.StepCost = step_cost\n",
        "\n",
        "    # define transition probabilities\n",
        "    self.TransitionProb = {}\n",
        "    for r in range(self.rows):\n",
        "      for c in range(self.cols):\n",
        "        state = (r,c)\n",
        "        if state not in self.TerminalStates:\n",
        "          for action in self.ActionSpace:\n",
        "            #move\n",
        "            next_state = list(state)\n",
        "            if action == 'U':\n",
        "              next_state[0] -= 1\n",
        "            elif action == 'D':\n",
        "              next_state[0] += 1\n",
        "            elif action == 'L':\n",
        "              next_state[1] -= 1\n",
        "            elif action == 'R':\n",
        "              next_state[1] += 1\n",
        "            next_state = tuple(next_state)\n",
        "\n",
        "            #check if valid\n",
        "            if next_state in self.StateSpace:\n",
        "              next_state_actual = next_state\n",
        "            else:\n",
        "              next_state_actual = state\n",
        "            \n",
        "            #assign transition probability\n",
        "            self.TransitionProb[(state,action,next_state_actual)] = 1\n",
        "\n",
        "    # visualise world\n",
        "    ## draw out cells, walls and reward locations.\n",
        "    self.World = np.array([[' ' for _ in range(cols)] for _ in range(rows)])\n",
        "    for wall in walls: self.World[wall[0],wall[1]] = '#'\n",
        "    for re in self.Rewards.keys():\n",
        "      if self.Rewards[re] > 0:\n",
        "        self.World[re[0],re[1]] = '+'\n",
        "      elif self.Rewards[re] < 0:\n",
        "        self.World[re[0],re[1]] = '-'\n",
        "\n",
        "    ##--------------------------------------------------------------------##\n",
        "\n",
        "    ## INITIALISED VALUES FOR LEARNING\n",
        "    # initialise states\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "   \n",
        "    # initialise state values \n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateVisitCounts = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    # initialise state action values\n",
        "    self.StateActionValues = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateActionVisitCounts = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    #self.StateActionValues = {(s,a):0 for a in self.ActionSpace for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    #self.StateActionVisitCounts = {(s,a):0 for a in self.ActionSpace for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    \n",
        "    # initialise random policy (here we assume NO KNOWLEDGE of the environment)\n",
        "    self.Policy = {s:{np.random.choice(['U','D','L','R']):1} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    # # initialise returns\n",
        "    # self.Returns = {s:[] for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]} #is this necessary?\n",
        "\n",
        "    ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## SETTINGS ##\n",
        "  def set_policy(self,policy_dict):\n",
        "    self.Policy = policy_dict\n",
        "  \n",
        "  def set_state_values(self,values_dict,reset=True):\n",
        "    self.StateValues = values_dict\n",
        "    if reset: self.StateVisitCounts = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  def set_state_action_values(self,actionvalues_dict,reset=True):\n",
        "    self.StateActionValues = actionvalues_dict\n",
        "    if reset: self.StateActionVisitCounts = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  def set_transition_proba(self,transition_dict):\n",
        "    self.TransitionProb = transition_dict\n",
        "    \n",
        "  def set_fixed_policy(self):\n",
        "    # set a fixed policy\n",
        "    self.Policy = {(0, 0): {'R':1},\n",
        "                  (0, 1): {'R':1},\n",
        "                  (0, 2): {'R':1},\n",
        "                  (1, 0): {'U':1},\n",
        "                  (1, 2): {'U':1},\n",
        "                  (2, 0): {'U':1},\n",
        "                  (2, 1): {'R':1},\n",
        "                  (2, 2): {'U':1},\n",
        "                  (2, 3): {'L':1}}\n",
        "  \n",
        "  def set_random_policy(self):\n",
        "    #self.Policy = {s:{np.random.choice(['U','D','L','R']):1} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    for state in self.Policy:\n",
        "      a_ = np.random.choice(self.ActionSpace)\n",
        "      self.Policy[state][a_] = 1\n",
        "\n",
        "\n",
        "  def set_equil_policy(self):\n",
        "    self.Policy = {s:{a:1/len(self.ActionSpace) for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  def set_V_from_Q(self):\n",
        "    for state,Qs in self.StateActionValues.items():\n",
        "      self.StateValues[state] = max(Qs.values())\n",
        "  \n",
        "  def set_state_visit_counts(self):\n",
        "    for state,SV in self.StateActionVisitCounts.items():\n",
        "      self.StateVisitCounts[state] = np.sum(list(SV.values()))\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "\n",
        "  ## GETTINGS ##\n",
        "  def get_all_states(self):\n",
        "    return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "  \n",
        "  def get_valid_states(self):\n",
        "    available_states = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    for wall in self.Walls: available_states.remove(wall) #set walls\n",
        "    for term in self.TerminalStates: available_states.remove(term) #set walls\n",
        "    return available_states\n",
        "\n",
        "  def get_next_state(self,state,action):\n",
        "    next_state = list(state)\n",
        "    if action == 'U':\n",
        "      next_state[0] -= 1\n",
        "    elif action == 'D':\n",
        "      next_state[0] += 1\n",
        "    elif action == 'L':\n",
        "      next_state[1] -= 1\n",
        "    elif action == 'R':\n",
        "      next_state[1] += 1\n",
        "    \n",
        "    if tuple(next_state) in self.StateSpace:\n",
        "      return tuple(next_state)\n",
        "    else:\n",
        "      return tuple(state)\n",
        "\n",
        "  def get_reward(self,next_state):\n",
        "    return self.Rewards.get(next_state,self.StepCost)\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## UTILS ##\n",
        "  def move(self,action,verbose=False):\n",
        "    # set previous state history first\n",
        "    self.PreviousState = self.CurrentState\n",
        "    \n",
        "    # perform move & update new state\n",
        "    self.CurrentState = self.get_next_state(self.PreviousState,action) #list(self.CurrentState)\n",
        "    \n",
        "    #print move\n",
        "    if verbose: print('Agent moved from %s to %s' % (self.PreviousState,self.CurrentState))\n",
        "    \n",
        "    # return reward\n",
        "    return self.Rewards.get(self.CurrentState,self.StepCost) #return defined rewards\n",
        "\n",
        "  def game_over(self):\n",
        "    return self.CurrentState in self.TerminalStates\n",
        "\n",
        "  def is_terminal(self,state):\n",
        "    return state in self.TerminalStates\n",
        "\n",
        "  def epsilon_greedy(self,eps=.1):\n",
        "    if np.random.rand() < (1 - eps): #for majority of the time, return best action (with ties broken randomly)\n",
        "      max_Q = max(self.StateActionValues[self.CurrentState].values())\n",
        "      max_a = []\n",
        "      for act,val in self.StateActionValues[self.CurrentState].items():\n",
        "        if val == max_Q:\n",
        "          max_a.append(act)\n",
        "      return np.random.choice(max_a)\n",
        "    else: #otherwise random action\n",
        "      return np.random.choice(self.ActionSpace)\n",
        "\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## RESETS ##\n",
        "  def reset_location(self,start_position=(2,0)):\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "\n",
        "  def reset_values(self):\n",
        "    # state\n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateVisitCounts = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    # state action\n",
        "    self.StateActionValues = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateActionVisitCounts = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "  \n",
        "  ## VISUALISERS ##\n",
        "  def visualise_world(self,view_agent_loc=True):\n",
        "    world = self.World.copy()\n",
        "\n",
        "    ## mark agent location\n",
        "    if view_agent_loc:\n",
        "      r,c = self.CurrentState\n",
        "      if self.CurrentState == self.PreviousState:\n",
        "        world[r,c] = '*'\n",
        "      else:\n",
        "        world[r,c] = 'o'\n",
        "    \n",
        "    ## display\n",
        "    for r in world: \n",
        "      print('|'+'%s|' * len(r) %tuple(r))\n",
        "\n",
        "  def visualise_values(self):\n",
        "    values = np.zeros((self.rows,self.cols))\n",
        "\n",
        "    for state,vals in self.StateValues.items():\n",
        "      r,c = state\n",
        "      values[r,c] = vals\n",
        "    \n",
        "    for rows in values:\n",
        "      print('|',end=\"\")\n",
        "      for c in rows:\n",
        "        if c >= 0:\n",
        "          print(' %.2f|' % c, end=\"\")\n",
        "        else:\n",
        "          print('%.2f|' % c, end=\"\")\n",
        "      print('\\n',end=\"\")\n",
        "  \n",
        "  def visualise_policy(self):\n",
        "    polmap = self.World.copy() #np.array([[' ' for _ in range(self.cols)] for _ in range(rows)])\n",
        "    \n",
        "    #get only valid policies\n",
        "    valid_policies = self.Policy.copy()\n",
        "    for wall in self.Walls: valid_policies.pop(wall,None) #set walls\n",
        "    for term in self.TerminalStates: valid_policies.pop(term,None) #set walls\n",
        "    \n",
        "    #fill in cells with arrows depicting policies\n",
        "    for state,act in valid_policies.items():\n",
        "      r,c = state\n",
        "      a = []\n",
        "      for ak,vk in act.items():\n",
        "        if vk == max(act.values()):\n",
        "          a.append(ak)\n",
        "      action = np.random.choice(a)\n",
        "      if action == 'U':\n",
        "        polmap[r,c] = '^'\n",
        "      elif action == 'D':\n",
        "        polmap[r,c] = 'v'\n",
        "      elif action == 'L':\n",
        "        polmap[r,c] = '<'\n",
        "      elif action == 'R':\n",
        "        polmap[r,c] = '>'\n",
        "    for p in polmap: print('|'+'%s|' * len(p) %tuple(p))\n",
        "\n",
        "  def visualise_state_visit_counts(self):\n",
        "    values = np.zeros((self.rows,self.cols))\n",
        "    max_vs = max(self.StateVisitCounts.values()) #for formatting\n",
        "    for state,vals in self.StateVisitCounts.items():\n",
        "      r,c = state\n",
        "      values[r,c] = vals\n",
        "    for rows in values:\n",
        "      print('|',end=\"\")\n",
        "      for c in rows:\n",
        "        eval(\"print('%\"+str(len(str(max_vs)))+\"d|' % c, end='')\")\n",
        "      print('\\n',end=\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zBPMlU_hyTp"
      },
      "source": [
        "### solving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "PBU31RgYeq-e",
        "outputId": "f74372b8-f7fd-475e-8014-142a7a5cf286"
      },
      "source": [
        "## MONTE CARLO CONTROL PROBLEM - WITH EXPLORING STARTS\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "MAX_EP_STEPS = 20\n",
        "\n",
        "## initialise environment\n",
        "grid = GridWorld4()\n",
        "grid.set_random_policy()\n",
        "print('init policy')\n",
        "grid.visualise_policy()\n",
        "available_states = grid.get_valid_states() #shortcut to define available states\n",
        "\n",
        "## keep track of changes to Q-values\n",
        "deltas = []\n",
        "\n",
        "## interact until convergence\n",
        "# SETUP\n",
        "for _ in range(10000):\n",
        "  biggest_change = 0\n",
        "  ## START PLAYING EPISODE\n",
        "  # exploring start\n",
        "  state = available_states[np.random.choice(len(available_states))] #randomise start location\n",
        "  action = np.random.choice(grid.ActionSpace) #pick random action\n",
        "  grid.reset_location(state) #set start locations\n",
        "  \n",
        "  # initialise lists to keep track of agent history\n",
        "  state_history = [state]\n",
        "  action_history = [action]\n",
        "  reward_history = [None]\n",
        "\n",
        "  # play up to MAX_EP_STEPS steps\n",
        "  for i in range(MAX_EP_STEPS):\n",
        "    #get reward\n",
        "    reward = grid.move(action) #note that this method implicitly updates grid.CurrentState\n",
        "    reward_history.append(reward)\n",
        "\n",
        "    #record new state\n",
        "    state_history.append(grid.CurrentState)\n",
        "\n",
        "    #check if game over\n",
        "    if grid.game_over(): \n",
        "      #if agent at terminal episode\n",
        "      action_history.append(None)\n",
        "      break\n",
        "    else:\n",
        "      #select new action, append to history\n",
        "      action = max(grid.Policy[grid.CurrentState], key=grid.Policy[grid.CurrentState].get)\n",
        "      action_history.append(action)\n",
        "\n",
        "\n",
        "\n",
        "  ## CALCULATE RETURNS    \n",
        "  state_action_history = list(zip(state_history,action_history))\n",
        "  G=0\n",
        "  for t in range(len(state_history)-2,-1,-1): #reverse order\n",
        "    sh = state_history[t]\n",
        "    ah = action_history[t]\n",
        "    rh = reward_history[t+1]\n",
        "\n",
        "    # increase state-action visit by 1\n",
        "    grid.StateActionVisitCounts[sh][ah] += 1\n",
        "\n",
        "    # sum returns\n",
        "    G = rh + GAMMA * G\n",
        "\n",
        "    if (sh,ah) not in state_action_history[:t]: #check for first-visit\n",
        "      old_Q = grid.StateActionValues[sh][ah]\n",
        "      #returns[sh][ah].append(G)\n",
        "      grid.StateActionValues[sh][ah] += (1/grid.StateActionVisitCounts[sh][ah])*(G - grid.StateActionValues[sh][ah]) #Q-value\n",
        "      #grid.StateActionValues[sh][ah] = np.mean(returns[sh][ah])\n",
        "      \n",
        "      #update policy\n",
        "      max_Q = max(grid.StateActionValues[sh].values())\n",
        "      max_acts = [a for a,v in grid.StateActionValues[sh].items() if v == max_Q] #use to break ties\n",
        "      grid.Policy[sh] = {np.random.choice(max_acts):1} #randomly break ties if multiple actions have same Q values\n",
        "\n",
        "      #store biggest change\n",
        "      biggest_change = max(biggest_change,np.abs(old_Q - grid.StateActionValues[sh][ah]))\n",
        "  \n",
        "  deltas.append(biggest_change)\n",
        "\n",
        "  ## breakpoint\n",
        "\n",
        "  \n",
        "  # if np.mean(deltas) < CONVERGENCE_LIMIT:\n",
        "  #   break\n",
        "\n",
        "#find V\n",
        "grid.set_V_from_Q()\n",
        "\n",
        "\n",
        "\n",
        "print('\\nfinal policy')\n",
        "grid.visualise_policy()\n",
        "print('\\nfinal values')\n",
        "grid.visualise_values()\n",
        "print('\\n\\n')\n",
        "\n",
        "plt.plot(deltas)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init policy\n",
            "|^|v|^|+|\n",
            "|v|#|^|-|\n",
            "|v|<|^|v|\n",
            "\n",
            "final policy\n",
            "|>|>|>|+|\n",
            "|^|#|^|-|\n",
            "|>|>|^|<|\n",
            "\n",
            "final values\n",
            "| 0.80| 0.90| 1.00| 0.00|\n",
            "| 0.73| 0.00| 0.90| 0.00|\n",
            "| 0.64| 0.72| 0.80| 0.63|\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATJUlEQVR4nO3dfZBddX3H8fc3u3kCkpCYJYQkkKDxIbRVcItQndbxAQNTQ53aGqYqWpWZVlpbnXaSsUMVp9Oq1alMU5X6VJ0KonUkQmy0QHXKCLLIY4LBFTAPINmExwRCsrvf/nFP8Gazm71J7ubu/e37NXMn5/zO757zPfvbfO7Zc+69JzITSVL7m9TqAiRJzWGgS1IhDHRJKoSBLkmFMNAlqRCdrdrw3Llzc/Hixa3avCS1pdtvv31HZnYNt6xlgb548WJ6enpatXlJaksR8cuRlnnKRZIKYaBLUiEMdEkqhIEuSYUw0CWpEKMGekR8KSK2R8S9IyyPiLgiInoj4u6IOKv5ZUqSRtPIEfpXgOWHWH4+sLR6XAJ89ujLkiQdrlEDPTN/BDx2iC4XAl/NmluAEyNifrMKHHaDa27mqz9+aCw3IUltpxnn0BcAW+rmt1ZtB4mISyKiJyJ6+vr6jmhju57r564tT3DZtRuO6PmSVKpjelE0M6/MzO7M7O7qGvaTq6MaGPCGHJI0nGYE+jZgUd38wqpNknQMNSPQ1wLvrN7tcg7wZGY+0oT1SpIOw6hfzhURVwGvBeZGxFbg74HJAJn5OWAdcAHQCzwDvHusipUkjWzUQM/Mi0ZZnsD7m1aRJOmI+ElRSSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIK0X6BHq0uQJLGp/YLdEnSsAx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUiIYCPSKWR8SmiOiNiFXDLD81Im6KiDsi4u6IuKD5pUqSDmXUQI+IDmANcD6wDLgoIpYN6fZ3wDWZeSawEvi3Zhf663rGas2S1N4aOUI/G+jNzAcycy9wNXDhkD4JzKymZwEPN69ESVIjGgn0BcCWuvmtVVu9jwBvj4itwDrgL4ZbUURcEhE9EdHT19d3BOVKkkbSrIuiFwFfycyFwAXA1yLioHVn5pWZ2Z2Z3V1dXU3atCQJGgv0bcCiuvmFVVu99wDXAGTmj4FpwNxmFChJakwjgX4bsDQilkTEFGoXPdcO6bMZeD1ARLyMWqB7TkWSjqFRAz0z+4FLgfXAfdTezbIhIi6PiBVVtw8B74uIu4CrgHdlZo5V0ZKkg3U20ikz11G72Fnfdlnd9Ebg1c0tTZJ0OPykqCQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBWi7QI9Wl2AJI1TbRfokqThGeiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhGgr0iFgeEZsiojciVo3Q548jYmNEbIiIrze3TEnSaDpH6xARHcAa4I3AVuC2iFibmRvr+iwFVgOvzszHI+KksSpYkjS8Ro7QzwZ6M/OBzNwLXA1cOKTP+4A1mfk4QGZub26ZkqTRNBLoC4AtdfNbq7Z6LwZeHBE3R8QtEbF8uBVFxCUR0RMRPX19fUdWsSRpWM26KNoJLAVeC1wE/HtEnDi0U2ZemZndmdnd1dXVpE1LkqCxQN8GLKqbX1i11dsKrM3MfZn5IHA/tYCXJB0jjQT6bcDSiFgSEVOAlcDaIX2+Q+3onIiYS+0UzANNrFOSNIpRAz0z+4FLgfXAfcA1mbkhIi6PiBVVt/XAzojYCNwE/E1m7hyroiVJBxv1bYsAmbkOWDek7bK66QQ+WD0kSS3gJ0UlqRAGuiQVou0CPSJaXYIkjUttF+iSpOEZ6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIRoK9IhYHhGbIqI3IlYdot8fRkRGRHfzSpQkNWLUQI+IDmANcD6wDLgoIpYN028G8AHg1mYXOZI/WHPzsdqUJI17jRyhnw30ZuYDmbkXuBq4cJh+HwM+DuxpYn2HdOeWJ47VpiRp3Gsk0BcAW+rmt1Ztz4uIs4BFmXn9oVYUEZdERE9E9PT19R12sZKkkR31RdGImAR8GvjQaH0z88rM7M7M7q6urqPdtCSpTiOBvg1YVDe/sGrbbwbwG8D/RsRDwDnAWi+MStKx1Uig3wYsjYglETEFWAms3b8wM5/MzLmZuTgzFwO3ACsys2dMKpYkDWvUQM/MfuBSYD1wH3BNZm6IiMsjYsVYFzhMPcd6k5LUFjob6ZSZ64B1Q9ouG6Hva4++LEnS4fKTopJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFaLtA/36ux9pdQmSNC60faC//+s/bXUJkjQutH2gS5JqDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCtF2gZ6sLkKRxqu0CXZI0PANdkgphoEtSIQx0SSqEgS5JhSgi0Bevup4f3d/X6jIkqaUaCvSIWB4RmyKiNyJWDbP8gxGxMSLujogbIuK05pd6aOvueeRYb1KSxpVRAz0iOoA1wPnAMuCiiFg2pNsdQHdm/hbwLeATzS5UknRojRyhnw30ZuYDmbkXuBq4sL5DZt6Umc9Us7cAC5tb5ujSTxxJmuAaCfQFwJa6+a1V20jeA3xvuAURcUlE9ERET1+f57wlqZmaelE0It4OdAOfHG55Zl6Zmd2Z2d3V1dXMTUvShNfZQJ9twKK6+YVV2wEi4g3Ah4Hfy8znmlOeJKlRjRyh3wYsjYglETEFWAmsre8QEWcCnwdWZOb25pcpSRrNqIGemf3ApcB64D7gmszcEBGXR8SKqtsngROAb0bEnRGxdoTVjZn0exglTXCNnHIhM9cB64a0XVY3/YYm1yVJOkxFfFJUkmSgS1IxDHRJKkQxge4nRSVNdMUEuiRNdAa6JBXCQJekQhjoklSIYgLda6KSJrq2C3TfzSJJw2u7QB/J3VufYPGq67lzyxOtLkWSWqKYQL//0V0A3Hjfoy2uRJJao5hAl6SJzkCXpEIUF+heM5U0UZUX6Ca6pAmquEDf/vSeVpcgSS1RXKBf07O11SVIUksUF+iSNFEZ6JJUiCIDPTN5oG9Xq8uQpGOqyED/8s0P8bpP/dCvAZA0oRQZ6HdUQf7LnbtbXIkkHTtFBnq0ugBJaoEyA71KdD9kJGkiKTLQJWkiKjrQ0292kTSBFBno1975MABP7+knPe8iaYIoMtD3u+zaDSxZvY6rfrL5+baHduw25CUVqbPVBRwLq799D6u/fQ/zZ03jkSdrX9715pefwhUrX8GWx55l3qypTO3saHGVknR0JkSg77c/zAG+e9fDfPeuhw9Y/tEVZ/COc05jx+7nOPsfbuD6v3wNLz15Jh2TfCOkpPEvGjn9EBHLgc8AHcAXMvOfhiyfCnwVeCWwE3hbZj50qHV2d3dnT0/PYRf85LP7ePlHv3/Yz2u20+cez1vOXMAZC2ayt3+Qs06bzcxpk3n0qT3MnzWdyR3Bs/sGmNrZ4QuCpKaJiNszs3u4ZaMeoUdEB7AGeCOwFbgtItZm5sa6bu8BHs/MF0XESuDjwNuOvvTx64Edu/nUD+5vdRlj4pWnzeb2Xz4OwJzjp/CSeTN44UnH8+Sz/Tz65B7u2PI4+waS0+cez0Amv/PCubzupSfxvXsf4cXzZnDjfdtZOu8EJndM4qSZU9m88xlOnjWNzY89w3nLTmb2cZO59+GneGHX8ex+boCl805g2xPPMvu4Keza08/Te/ZxetcJTJs8iZ279zLnuCnsHRhkWmcH/YOD7Ni1l5ecPIPdz/XzXP8gs6ZPpn9wkM07n+HUFxxHRwT7BpLjpnYwMJA8u2+AWdMnEwGDCdMn106vPb1nHx2TgumTO9g3kHR2BJ2Tgl3P9TO5YxJTOyexd2CQTOisXpQnRbCnv/ZCPTCYv26ve9Hef5AU1QciMpOIeP7f4foMDuYB66hX/7yh7UO3s39+6LaGtqlMox6hR8S5wEcy803V/GqAzPzHuj7rqz4/johO4FdAVx5i5Ud6hP7F/3uQj123cfSOksbEcVM6eGbvwEHt82ZOpX8g2bl7L8AB16wWzZnOlseefb5vBMyfOY1Hn36OgcFk5rROpnR20Dkp6Kgemx97BoAZ0zoJai+aQe0FK6p17Ni19/n1ZcLC2dPZuWsvp5w4bVy/eH3g9Ut588tPOaLnHtUROrAA2FI3vxV41Uh9MrM/Ip4EXgDsGFLIJcAlAKeeempDxQ+1aPb0Qy4/b9k8vr/x0SNatzTWVv72Iq6+bcvoHceBBSdOZ9sTzx7U/tKTZ3DSjGn894ZfPd/2ljMXMKVjEnv6B7j2zoe54DdP5oSpnfRu38VPNz/BGfNnsWTuCfzo/j6gFuavftFcAH54fx/nvvAFHD+1k4GBZN/gIAODyebHnuHUOcfxupeeBNT+0khgMJPM2v2Dex56jPsf3cXLTp7JxkeeYlIEZ5wyk3kzp435z+dozJo+eUzW28gR+luB5Zn53mr+HcCrMvPSuj73Vn22VvO/qPrsGG6dcORH6JI0kR3qCL2R96FvAxbVzS+s2obtU51ymUXt4qgk6RhpJNBvA5ZGxJKImAKsBNYO6bMWuLiafitw46HOn0uSmm/Uc+jVOfFLgfXU3rb4pczcEBGXAz2ZuRb4IvC1iOgFHqMW+pKkY6ihDxZl5jpg3ZC2y+qm9wB/1NzSJEmHo+jvcpGkicRAl6RCGOiSVAgDXZIK0dCXc43JhiP6gF8e4dPnMuRTqBOA+zwxuM8Tw9Hs82mZ2TXcgpYF+tGIiJ6RPilVKvd5YnCfJ4ax2mdPuUhSIQx0SSpEuwb6la0uoAXc54nBfZ4YxmSf2/IcuiTpYO16hC5JGsJAl6RCtF2gR8TyiNgUEb0RsarV9RypiFgUETdFxMaI2BARH6ja50TEDyLi59W/s6v2iIgrqv2+OyLOqlvXxVX/n0fExSNtc7yIiI6IuCMirqvml0TErdW+faP6mmYiYmo131stX1y3jtVV+6aIeFNr9qQxEXFiRHwrIn4WEfdFxLmlj3NE/HX1e31vRFwVEdNKG+eI+FJEbK9u8LO/rWnjGhGvjIh7qudcEdHAPfUys20e1L6+9xfA6cAU4C5gWavrOsJ9mQ+cVU3PAO4HlgGfAFZV7auAj1fTFwDfAwI4B7i1ap8DPFD9O7uant3q/Rtl3z8IfB24rpq/BlhZTX8O+LNq+s+Bz1XTK4FvVNPLqrGfCiypfic6Wr1fh9jf/wDeW01PAU4seZyp3ZLyQWB63fi+q7RxBn4XOAu4t66taeMK/KTqG9Vzzx+1plb/UA7zB3gusL5ufjWwutV1NWnfrgXeCGwC5ldt84FN1fTngYvq+m+qll8EfL6u/YB+4+1B7Y5XNwCvA66rfll3AJ1Dx5jad/CfW013Vv1i6LjX9xtvD2p373qQ6g0IQ8evxHHm1/cYnlON23XAm0ocZ2DxkEBvyrhWy35W135Av5Ee7XbKZbgbVi9oUS1NU/2JeSZwKzAvMx+pFv0KmFdNj7Tv7fYz+Rfgb4HBav4FwBOZ2V/N19d/wM3Hgf03H2+nfV4C9AFfrk4zfSEijqfgcc7MbcA/A5uBR6iN2+2UPc77NWtcF1TTQ9sPqd0CvTgRcQLwX8BfZeZT9cuy9tJczPtKI+L3ge2ZeXurazmGOqn9Wf7ZzDwT2E3tT/HnFTjOs4ELqb2YnQIcDyxvaVEt0IpxbbdAb+SG1W0jIiZTC/P/zMxvV82PRsT8avl8YHvVPtK+t9PP5NXAioh4CLia2mmXzwAnRu3m4nBg/SPdfLyd9nkrsDUzb63mv0Ut4Ese5zcAD2ZmX2buA75NbexLHuf9mjWu26rpoe2H1G6B3sgNq9tCdcX6i8B9mfnpukX1N9y+mNq59f3t76yulp8DPFn9abceOC8iZldHRudVbeNOZq7OzIWZuZja2N2YmX8C3ETt5uJw8D4Pd/PxtcDK6t0RS4Cl1C4gjTuZ+StgS0S8pGp6PbCRgseZ2qmWcyLiuOr3fP8+FzvOdZoyrtWypyLinOpn+M66dY2s1RcVjuAixAXU3hHyC+DDra7nKPbjNdT+HLsbuLN6XEDt3OENwM+B/wHmVP0DWFPt9z1Ad926/hTorR7vbvW+Nbj/r+XX73I5ndp/1F7gm8DUqn1aNd9bLT+97vkfrn4Wm2jg6n+L9/UVQE811t+h9m6GoscZ+CjwM+Be4GvU3qlS1DgDV1G7RrCP2l9i72nmuALd1c/vF8C/MuTC+nAPP/ovSYVot1MukqQRGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEP8PJKRb4GsaEIAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF7XUijnmI_H"
      },
      "source": [
        "**Monte-Carlo Policy Iteration Without Exploring Starts**\n",
        "* However, exploring starts are usually impractical. This is because, in the real world, we do not have a complete picture of all possible states.\n",
        "* To account for this problem, we utilise $\\epsilon$-greedy MC control.\n",
        "* Initialise a policy where $\\pi(a|s) > 0, \\forall a,s$.\n",
        "* To update the policy, we do the following steps:\n",
        "$$a^{*} = \\arg \\max_{a} Q(s_{t},a)$$\n",
        "$$\\pi(a^{*}|s_{t}) = 1 - \\epsilon + \\frac{\\epsilon}{|A|}$$\n",
        "$$\\pi(a|s_{t}) = \\frac{\\epsilon}{|A|}, \\forall a \\not= a^{*}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "Yu2QZKOcsdUU",
        "outputId": "660e0fea-cff9-4a52-a538-7cb60bc9f3ce"
      },
      "source": [
        "## MONTE CARLO CONTROL PROBLEM - WITHOUT EXPLORING STARTS\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "MAX_EP_STEPS = 20\n",
        "EPS = 0.3\n",
        "\n",
        "## initialise environment\n",
        "grid = GridWorld4(step_cost=0)\n",
        "grid.set_equil_policy()\n",
        "print('init policy')\n",
        "grid.visualise_policy()\n",
        "available_states = grid.get_valid_states() #shortcut to define available states\n",
        "\n",
        "## keep track of changes to Q-values\n",
        "deltas = []\n",
        "\n",
        "## interact until convergence\n",
        "# SETUP\n",
        "for _ in range(10000):\n",
        "  biggest_change = 0\n",
        "  ## START PLAYING EPISODE\n",
        "  grid.reset_location() #reset start location after every episode\n",
        "\n",
        "  # initialise lists to keep track of agent history\n",
        "  state_history = [grid.CurrentState]\n",
        "  action_history = [grid.epsilon_greedy(EPS)]\n",
        "  reward_history = [None]\n",
        "\n",
        "  # play up to MAX_EP_STEPS steps\n",
        "  for i in range(MAX_EP_STEPS):\n",
        "    #get reward\n",
        "    reward = grid.move(action) #note that this method implicitly updates grid.CurrentState\n",
        "    reward_history.append(reward)\n",
        "\n",
        "    #record new state\n",
        "    state_history.append(grid.CurrentState)\n",
        "\n",
        "    #check if game over\n",
        "    if grid.game_over(): \n",
        "      #if agent at terminal episode\n",
        "      action_history.append(None)\n",
        "      break\n",
        "    else:\n",
        "      #select new action, append to history\n",
        "      action = grid.epsilon_greedy(EPS)\n",
        "      action_history.append(action)\n",
        "\n",
        "\n",
        "  ## CALCULATE RETURNS    \n",
        "  state_action_history = list(zip(state_history,action_history))\n",
        "  G=0\n",
        "  for t in range(len(state_history)-2,-1,-1): #reverse order\n",
        "    sh = state_history[t]\n",
        "    ah = action_history[t]\n",
        "    rh = reward_history[t+1]\n",
        "\n",
        "    # increase state-action visit by 1\n",
        "    grid.StateActionVisitCounts[sh][ah] += 1\n",
        "\n",
        "    # sum returns\n",
        "    G = rh + GAMMA * G\n",
        "\n",
        "    if (sh,ah) not in state_action_history[:t]: #check for first-visit\n",
        "      old_Q = grid.StateActionValues[sh][ah]\n",
        "      #returns[sh][ah].append(G)\n",
        "      grid.StateActionValues[sh][ah] += (1/grid.StateActionVisitCounts[sh][ah])*(G - grid.StateActionValues[sh][ah]) #Q-value\n",
        "      #grid.StateActionValues[sh][ah] = np.mean(returns[sh][ah])\n",
        "      \n",
        "      #update policy\n",
        "      max_Q = max(grid.StateActionValues[sh].values())\n",
        "      max_acts = [a for a,v in grid.StateActionValues[sh].items() if v == max_Q] #use to break ties\n",
        "      \n",
        "      grid.Policy[sh] = {a:EPS/len(grid.ActionSpace) for a in grid.ActionSpace} #update all with equal 1-eps probability\n",
        "      grid.Policy[sh][np.random.choice(max_acts)] = 1 - EPS + (EPS/len(grid.ActionSpace)) #reassign max prob to best action (ties broken randomly)\n",
        "\n",
        "      #store biggest change\n",
        "      biggest_change = max(biggest_change,np.abs(old_Q - grid.StateActionValues[sh][ah]))\n",
        "  \n",
        "  deltas.append(biggest_change)\n",
        "\n",
        "  ## breakpoint\n",
        "\n",
        "  \n",
        "  # if np.mean(deltas) < CONVERGENCE_LIMIT:\n",
        "  #   break\n",
        "\n",
        "#find V\n",
        "grid.set_V_from_Q()\n",
        "\n",
        "#update state-visit counts\n",
        "grid.set_state_visit_counts()\n",
        "\n",
        "print('\\nfinal policy')\n",
        "grid.visualise_policy()\n",
        "print('\\nfinal values')\n",
        "grid.visualise_values()\n",
        "print('\\n\\n')\n",
        "\n",
        "plt.plot(deltas)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init policy\n",
            "|<|v|v|+|\n",
            "|^|#|v|-|\n",
            "|<|^|<|v|\n",
            "\n",
            "final policy\n",
            "|>|>|>|+|\n",
            "|^|#|^|-|\n",
            "|^|>|^|<|\n",
            "\n",
            "final values\n",
            "| 0.73| 0.85| 1.00| 0.00|\n",
            "| 0.63| 0.00| 0.84| 0.00|\n",
            "| 0.44| 0.50| 0.59| 0.49|\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2xKYLlIGR9w"
      },
      "source": [
        "# **Temporal Difference learning**\n",
        "\n",
        "* Unlike MC-learning, where we could only update our values after sampling the full return (i.e. only after episode has terminated), TD-learning updates the values towards an _estimated_ return.\n",
        "* TD is usually defined by a hyperparameter $\\lambda \\in [0,1]$, that determines the proportion of steps to look ahead (up to episode termination), so as to estimate returns.\n",
        " * MC-learning is essentially hyperparameterised by $\\lambda = 1$\n",
        " * One-step ahead TD-learning is hyperparameterised by $\\lambda = 0$, and so is commonly referred to as TD(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-djAPgwUp0j"
      },
      "source": [
        "## TD(0) Policy Evaluation\n",
        "\n",
        "--- \n",
        "\n",
        "* Previously, to evaluate a policy, we averaged returns across all steps. However, sometimes episodes may have no clear termination points.\n",
        "* As such, we utilise Exponentially Weighted Moving Average (EWMA) to iteratively update state/action values, that is to say:\n",
        "$$V_{\\pi}(s_{t}) = V_{\\pi}(s_{t}) + \\alpha[G_{t} - V_{\\pi}(s_{t})]$$\n",
        "Where we use a constant $\\alpha$\n",
        "* However note that this still requires a return value of $G$, which by definition can only be obtained after an episode terminates. We instead utilise the dynamic programming method of _estimating_ the return using the value of the next state, $V_{\\pi}(s_{t+1})$, to update our values:\n",
        "$$V_{\\pi}(s_{t}) = V_{\\pi}(s_{t}) + \\alpha[r + \\gamma V_{\\pi}(s_{t+1}) - V_{\\pi}(s_{t})]$$\n",
        "This allows values to be updated even as soon as 1 reward is obtained (negating issues with long/infinitely-long episodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx69tK2GijUy"
      },
      "source": [
        "### environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D14FKsrGRwf"
      },
      "source": [
        "class GridWorld5:\n",
        "  def __init__(self,rows=3,cols=4,start_position=(2,0),walls=[(1,1)],rewards_dict={(0,3):1,(1,3):-1},step_cost=0):\n",
        "    '''pass in wall as a list'''\n",
        "        \n",
        "    ## ENVIRONMENT MODEL\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "\n",
        "    # create state space\n",
        "    self.StateSpace = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    self.Walls = walls\n",
        "    for wall in self.Walls: self.StateSpace.remove(wall) #set walls\n",
        "    \n",
        "    # define action space\n",
        "    self.ActionSpace = ('U','D','L','R')\n",
        "    \n",
        "    # define rewards\n",
        "    self.Rewards = rewards_dict\n",
        "    self.TerminalStates = list(self.Rewards.keys())\n",
        "\n",
        "    # define step cost\n",
        "    self.StepCost = step_cost\n",
        "\n",
        "    # # define transition probabilities\n",
        "    # self.TransitionProb = {}\n",
        "    # for r in range(self.rows):\n",
        "    #   for c in range(self.cols):\n",
        "    #     state = (r,c)\n",
        "    #     if state not in self.TerminalStates:\n",
        "    #       for action in self.ActionSpace:\n",
        "    #         #move\n",
        "    #         next_state = list(state)\n",
        "    #         if action == 'U':\n",
        "    #           next_state[0] -= 1\n",
        "    #         elif action == 'D':\n",
        "    #           next_state[0] += 1\n",
        "    #         elif action == 'L':\n",
        "    #           next_state[1] -= 1\n",
        "    #         elif action == 'R':\n",
        "    #           next_state[1] += 1\n",
        "    #         next_state = tuple(next_state)\n",
        "\n",
        "    #         #check if valid\n",
        "    #         if next_state in self.StateSpace:\n",
        "    #           next_state_actual = next_state\n",
        "    #         else:\n",
        "    #           next_state_actual = state\n",
        "            \n",
        "    #         #assign transition probability\n",
        "    #         self.TransitionProb[(state,action,next_state_actual)] = 1\n",
        "\n",
        "    # visualise world\n",
        "    ## draw out cells, walls and reward locations.\n",
        "    self.World = np.array([[' ' for _ in range(cols)] for _ in range(rows)])\n",
        "    for wall in walls: self.World[wall[0],wall[1]] = '#'\n",
        "    for re in self.Rewards.keys():\n",
        "      if self.Rewards[re] > 0:\n",
        "        self.World[re[0],re[1]] = '+'\n",
        "      elif self.Rewards[re] < 0:\n",
        "        self.World[re[0],re[1]] = '-'\n",
        "\n",
        "    ##--------------------------------------------------------------------##\n",
        "\n",
        "    ## INITIALISED VALUES FOR LEARNING\n",
        "    # initialise states\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "   \n",
        "    # initialise state values \n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateVisitCounts = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "    # initialise state action values\n",
        "    self.StateActionValues = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateActionVisitCounts = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "  \n",
        "    # initialise random policy (here we assume NO KNOWLEDGE of the environment)\n",
        "    self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    for state in self.Policy:\n",
        "      a_ = np.random.choice(self.ActionSpace)\n",
        "      self.Policy[state][a_] = 1\n",
        "\n",
        "    ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## SETTINGS ##\n",
        "  def set_policy(self,policy_dict):\n",
        "    self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    for state,action in policy_dict.items():\n",
        "      for act,val in action.items():\n",
        "        self.Policy[state][act] = val\n",
        "  \n",
        "  def set_state_values(self,values_dict,reset=True):\n",
        "    self.StateValues = values_dict\n",
        "    if reset: self.StateVisitCounts = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  def set_state_action_values(self,actionvalues_dict,reset=True):\n",
        "    self.StateActionValues = actionvalues_dict\n",
        "    if reset: self.StateActionVisitCounts = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  def set_transition_proba(self,transition_dict):\n",
        "    self.TransitionProb = transition_dict\n",
        "    \n",
        "  def set_fixed_policy(self):\n",
        "    # set a fixed policy\n",
        "    self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    \n",
        "    fixed_policy = {(0, 0): {'R':1},\n",
        "                    (0, 1): {'R':1},\n",
        "                    (0, 2): {'R':1},\n",
        "                    (1, 0): {'U':1},\n",
        "                    (1, 2): {'U':1},\n",
        "                    (2, 0): {'U':1},\n",
        "                    (2, 1): {'R':1},\n",
        "                    (2, 2): {'U':1},\n",
        "                    (2, 3): {'L':1}}\n",
        "\n",
        "    for state,action in fixed_policy.items():\n",
        "      for act,val in action.items():\n",
        "        self.Policy[state][act] = val\n",
        "  \n",
        "  def set_random_policy(self):\n",
        "    #self.Policy = {s:{np.random.choice(['U','D','L','R']):1} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    for state in self.Policy:\n",
        "      a_ = np.random.choice(self.ActionSpace)\n",
        "      self.Policy[state][a_] = 1\n",
        "\n",
        "\n",
        "  def set_equil_policy(self):\n",
        "    self.Policy = {s:{a:1/len(self.ActionSpace) for a in self.ActionSpace} for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "\n",
        "  def set_V_from_Q(self):\n",
        "    for state,Qs in self.StateActionValues.items():\n",
        "      self.StateValues[state] = max(Qs.values())\n",
        "  \n",
        "  def set_state_visit_counts(self):\n",
        "    for state,SV in self.StateActionVisitCounts.items():\n",
        "      self.StateVisitCounts[state] = np.sum(list(SV.values()))\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "\n",
        "  ## GETTINGS ##\n",
        "  def get_all_states(self):\n",
        "    return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "  \n",
        "  def get_valid_states(self):\n",
        "    available_states = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    for wall in self.Walls: available_states.remove(wall) #set walls\n",
        "    for term in self.TerminalStates: available_states.remove(term) #set walls\n",
        "    return available_states\n",
        "\n",
        "  def get_next_state(self,state,action):\n",
        "    next_state = list(state)\n",
        "    if action == 'U':\n",
        "      next_state[0] -= 1\n",
        "    elif action == 'D':\n",
        "      next_state[0] += 1\n",
        "    elif action == 'L':\n",
        "      next_state[1] -= 1\n",
        "    elif action == 'R':\n",
        "      next_state[1] += 1\n",
        "    \n",
        "    if tuple(next_state) in self.StateSpace:\n",
        "      return tuple(next_state)\n",
        "    else:\n",
        "      return tuple(state)\n",
        "\n",
        "  def get_reward(self,next_state):\n",
        "    return self.Rewards.get(next_state,self.StepCost)\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## UTILS ##\n",
        "  def move(self,action,verbose=False):\n",
        "    # set previous state history first\n",
        "    self.PreviousState = self.CurrentState\n",
        "    \n",
        "    # perform move & update new state\n",
        "    self.CurrentState = self.get_next_state(self.PreviousState,action) #list(self.CurrentState)\n",
        "    \n",
        "    #print move\n",
        "    if verbose: print('Agent moved from %s to %s' % (self.PreviousState,self.CurrentState))\n",
        "    \n",
        "    # return reward\n",
        "    return self.Rewards.get(self.CurrentState,self.StepCost) #return defined rewards\n",
        "\n",
        "  def game_over(self):\n",
        "    return self.CurrentState in self.TerminalStates\n",
        "\n",
        "  def is_terminal(self,state):\n",
        "    return state in self.TerminalStates\n",
        "\n",
        "  def next_action(self):\n",
        "    max_val = max(self.Policy[self.CurrentState].values())\n",
        "    max_a = []\n",
        "    for act,val in self.Policy[self.CurrentState].items():\n",
        "      if val == max_val:\n",
        "        max_a.append(act)\n",
        "    return np.random.choice(max_a)\n",
        "\n",
        "\n",
        "  def epsilon_greedy(self,based_on = 'policy',eps=.1):\n",
        "    if np.random.rand() < (1 - eps): #for majority of the time, return best action (with ties broken randomly)\n",
        "      max_a = []\n",
        "      if based_on == 'policy': #actions follow Policy\n",
        "        max_val = max(self.Policy[self.CurrentState].values())\n",
        "        for act,val in self.Policy[self.CurrentState].items():\n",
        "          if val == max_val:\n",
        "            max_a.append(act)\n",
        "            \n",
        "      elif based_on == 'Q': #action based on best State-action values\n",
        "        max_a = []\n",
        "        max_val = max(self.StateActionValues[self.CurrentState].values())\n",
        "        for act,val in self.StateActionValues[self.CurrentState].items():\n",
        "          if val == max_val:\n",
        "            max_a.append(act)\n",
        "\n",
        "      return np.random.choice(max_a)\n",
        "\n",
        "    else: #otherwise random action\n",
        "      return np.random.choice(self.ActionSpace)\n",
        "\n",
        "  def argmaxQ(self,state):\n",
        "    max_a = []\n",
        "    max_val = max(self.StateActionValues[state].values())\n",
        "    for act,val in self.StateActionValues[state].items():\n",
        "      if val == max_val:\n",
        "        max_a.append(act)\n",
        "    return np.random.choice(max_a)\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## RESETS ##\n",
        "  def reset_location(self,start_position=(2,0)):\n",
        "    self.StartingState = start_position\n",
        "    self.PreviousState = start_position\n",
        "    self.CurrentState = start_position\n",
        "\n",
        "  def reset_values(self):\n",
        "    # state\n",
        "    self.StateValues = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateVisitCounts = {s:0 for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    # state action\n",
        "    self.StateActionValues = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "    self.StateActionVisitCounts = {s:{a:0 for a in self.ActionSpace } for s in [(i,j) for i in range(self.rows) for j in range(self.cols)]}\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "  \n",
        "  ## VISUALISERS ##\n",
        "  def visualise_world(self,view_agent_loc=True):\n",
        "    world = self.World.copy()\n",
        "\n",
        "    ## mark agent location\n",
        "    if view_agent_loc:\n",
        "      r,c = self.CurrentState\n",
        "      if self.CurrentState == self.PreviousState:\n",
        "        world[r,c] = '*'\n",
        "      else:\n",
        "        world[r,c] = 'o'\n",
        "    \n",
        "    ## display\n",
        "    for r in world: \n",
        "      print('|'+'%s|' * len(r) %tuple(r))\n",
        "\n",
        "  def visualise_values(self):\n",
        "    values = np.zeros((self.rows,self.cols))\n",
        "\n",
        "    for state,vals in self.StateValues.items():\n",
        "      r,c = state\n",
        "      values[r,c] = vals\n",
        "    \n",
        "    for rows in values:\n",
        "      print('|',end=\"\")\n",
        "      for c in rows:\n",
        "        if c >= 0:\n",
        "          print(' %.2f|' % c, end=\"\")\n",
        "        else:\n",
        "          print('%.2f|' % c, end=\"\")\n",
        "      print('\\n',end=\"\")\n",
        "  \n",
        "  def visualise_policy(self):\n",
        "    polmap = self.World.copy() #np.array([[' ' for _ in range(self.cols)] for _ in range(rows)])\n",
        "    \n",
        "    #get only valid policies\n",
        "    valid_policies = self.Policy.copy()\n",
        "    for wall in self.Walls: valid_policies.pop(wall,None) #set walls\n",
        "    for term in self.TerminalStates: valid_policies.pop(term,None) #set walls\n",
        "    \n",
        "    #fill in cells with arrows depicting policies\n",
        "    for state,act in valid_policies.items():\n",
        "      r,c = state\n",
        "      a = []\n",
        "      for ak,vk in act.items():\n",
        "        if vk == max(act.values()):\n",
        "          a.append(ak)\n",
        "      action = np.random.choice(a)\n",
        "      if action == 'U':\n",
        "        polmap[r,c] = '^'\n",
        "      elif action == 'D':\n",
        "        polmap[r,c] = 'v'\n",
        "      elif action == 'L':\n",
        "        polmap[r,c] = '<'\n",
        "      elif action == 'R':\n",
        "        polmap[r,c] = '>'\n",
        "    for p in polmap: print('|'+'%s|' * len(p) %tuple(p))\n",
        "\n",
        "  def visualise_state_visit_counts(self):\n",
        "    values = np.zeros((self.rows,self.cols))\n",
        "    max_vs = max(self.StateVisitCounts.values()) #for formatting\n",
        "    for state,vals in self.StateVisitCounts.items():\n",
        "      r,c = state\n",
        "      values[r,c] = vals\n",
        "    for rows in values:\n",
        "      print('|',end=\"\")\n",
        "      for c in rows:\n",
        "        eval(\"print('%\"+str(len(str(max_vs)))+\"d|' % c, end='')\")\n",
        "      print('\\n',end=\"\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bZKAc7qilY6"
      },
      "source": [
        "### solver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "xWkEYQHwY_vq",
        "outputId": "ed971135-20c7-44f3-dda4-5e36f7127f05"
      },
      "source": [
        "## TD-LEARNING: POLICY EVALUTION\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "MAX_EP_STEPS = 20\n",
        "ALPHA = .1\n",
        "\n",
        "## initialise environment\n",
        "grid = GridWorld5()\n",
        "\n",
        "\n",
        "policy = {(0, 0): {'R':1},\n",
        "          (0, 1): {'R':1},\n",
        "          (0, 2): {'R':1},\n",
        "          (1, 0): {'U':1},\n",
        "          (1, 2): {'R':1},\n",
        "          (2, 0): {'U':1},\n",
        "          (2, 1): {'R':1},\n",
        "          (2, 2): {'R':1},\n",
        "          (2, 3): {'U':1}}\n",
        "\n",
        "grid.set_policy(policy)\n",
        "\n",
        "#grid.set_random_policy()\n",
        "print('init policy')\n",
        "grid.visualise_policy()\n",
        "\n",
        "\n",
        "## \n",
        "deltas = []\n",
        "#while True:\n",
        "for _ in range(10000):\n",
        "  ## start playing\n",
        "  grid.reset_location()\n",
        "  \n",
        "  delta = 0\n",
        "  while not grid.game_over():\n",
        "    #keep count of state visits\n",
        "    grid.StateVisitCounts[grid.CurrentState] += 1\n",
        "\n",
        "    #find next action\n",
        "    action = grid.epsilon_greedy()\n",
        "\n",
        "    #get reward\n",
        "    reward = grid.move(action) #here the agent has moved to s'\n",
        "    \n",
        "    #update state value\n",
        "    v_prev = grid.StateValues[grid.PreviousState]\n",
        "    v_next = grid.StateValues[grid.CurrentState]\n",
        "\n",
        "    grid.StateValues[grid.PreviousState] = v_prev + ALPHA*(reward + GAMMA*v_next - v_prev)\n",
        "    \n",
        "    #record change\n",
        "    delta = max(delta,np.abs(grid.StateValues[grid.PreviousState] - v_prev))\n",
        "  \n",
        "  deltas.append(delta)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "print('\\nfinal values')\n",
        "grid.visualise_values()\n",
        "print('\\nvisit counts')\n",
        "grid.visualise_state_visit_counts()\n",
        "print('\\n\\n')\n",
        "\n",
        "_ = plt.plot(deltas)\n",
        "  \n",
        "\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init policy\n",
            "|>|>|>|+|\n",
            "|^|#|>|-|\n",
            "|^|>|>|^|\n",
            "\n",
            "final values\n",
            "| 0.77| 0.88| 0.98| 0.00|\n",
            "| 0.67| 0.00|-0.98| 0.00|\n",
            "| 0.58|-0.75|-0.89|-0.99|\n",
            "\n",
            "visit counts\n",
            "|10850|10783|10279|    0|\n",
            "|10831|    0|  253|    0|\n",
            "|10799|  280|  280|  278|\n",
            "\n",
            "\n",
            "\n",
            "Error in callback <function flush_figures at 0x7fc03ce2e320> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWWNVZy6ul-P"
      },
      "source": [
        "## TD(0) Policy Improvement\n",
        "\n",
        "---\n",
        "* after we have evaluated a policy, we now have a few methods to improve it.\n",
        " * SARSA\n",
        " * Q-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebxyOpF8ul7Y"
      },
      "source": [
        "### SARSA\n",
        "\n",
        "* SARSA is (s,a,r,s',a'). SARSA is **_on-policy_**, the Q-function we are learning is the Q-function we are using in the environment\n",
        "* When it comes to prediction, we can use $V(s)$. But when it comes to control, we need to _compare actions_ to take, and so we must use the values derived from $Q(s,a)$\n",
        "* The version of TD(0)-learning for the Q-values is:\n",
        "$$Q_{\\pi}(s,a) = Q_{\\pi}(s,a) + \\alpha [r + \\gamma Q_{\\pi}(s',a') - Q_{\\pi}(s,a)]$$\n",
        "* We refer to the return that has to be estimated, $r + \\gamma Q_{\\pi}(s',a')$, as the **_target_**\n",
        "* To obtain the target, instead of following a given policy, our policy would be **_$\\epsilon$-greedy w.r.t $Q$_**\n",
        "$$a'=\\begin{cases}\n",
        "\\arg \\max_{a} Q_{\\pi}(s,a)  & P(1-\\epsilon) \n",
        "\\\\ a \\sim \\mathcal{A} & P(\\epsilon)  \n",
        "\\end{cases}$$\n",
        "That is to say, we use our most recent estimate of $Q$, to determine the best action to take most of the time, but with some chance of exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "vMy5gH5waXHW",
        "outputId": "2fe8eabb-0479-45f6-f05e-856dd8965da5"
      },
      "source": [
        "## TD-LEARNING: POLICY IMPROVEMENT - SARSA\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "MAX_EP_STEPS = 20\n",
        "ALPHA = .1\n",
        "\n",
        "## initialise environment\n",
        "grid = GridWorld5(step_cost=-.1)\n",
        "#no need to set a policy\n",
        "\n",
        "#grid.set_random_policy()\n",
        "print('init policy')\n",
        "grid.visualise_policy()\n",
        "\n",
        "\n",
        "## \n",
        "reward_hist = []\n",
        "#while True:\n",
        "for _ in range(10000):\n",
        "  ## start playing\n",
        "  grid.reset_location()\n",
        "\n",
        "  current_action = grid.epsilon_greedy('Q') # this is `a`\n",
        "  rh = 0\n",
        "  while not grid.game_over():\n",
        "    #keep count of state-action visits\n",
        "    grid.StateActionVisitCounts[grid.CurrentState][current_action] += 1\n",
        "\n",
        "    #get reward\n",
        "    reward = grid.move(current_action) #here the agent has moved to s'\n",
        "    rh += reward\n",
        "\n",
        "    #update state value\n",
        "    next_action = grid.epsilon_greedy('Q') #this is `a'`\n",
        "    q_prev = grid.StateActionValues[grid.PreviousState][current_action] #this is Q(s,a)\n",
        "    q_next = grid.StateActionValues[grid.CurrentState][next_action] #this is Q(s',a')\n",
        "\n",
        "    grid.StateActionValues[grid.PreviousState][current_action] = q_prev + ALPHA*(reward + GAMMA*q_next - q_prev)\n",
        "\n",
        "    #update a' to a\n",
        "    current_action = next_action\n",
        "    \n",
        "    ## record change\n",
        "    #delta = max(delta,np.abs(grid.StateActionValues[grid.PreviousState][current_action] - q_prev))\n",
        "\n",
        "  reward_hist.append(rh)\n",
        "\n",
        "#here, we should have obtained Q*. Now, set policy according to Q*\n",
        "policy_dict = {s:{a:0 for a in grid.ActionSpace} for s in [(i,j) for i in range(grid.rows) for j in range(grid.cols)]}\n",
        "for state in grid.get_valid_states():\n",
        "  Qs = grid.StateActionValues[state]\n",
        "  max_a = []\n",
        "  max_val = max(list(Qs.values()))\n",
        "  for act,val in Qs.items():\n",
        "    if val == max_val:\n",
        "      max_a.append(act)\n",
        "  policy_dict[state][np.random.choice(max_a)] = 1 \n",
        "  grid.StateValues[state] = max_val\n",
        "grid.Policy = policy_dict\n",
        "\n",
        "\n",
        "\n",
        "grid.set_V_from_Q()\n",
        "grid.set_state_visit_counts()\n",
        "    \n",
        "print('\\nfinal policy')\n",
        "grid.visualise_policy()\n",
        "print('\\nfinal values')\n",
        "grid.visualise_values()\n",
        "print('\\nvisit counts')\n",
        "grid.visualise_state_visit_counts()\n",
        "print('\\n\\n')\n",
        "\n",
        "_ = plt.plot(reward_hist)\n",
        "  \n",
        "\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init policy\n",
            "|v|^|v|+|\n",
            "|^|#|v|-|\n",
            "|^|<|^|<|\n",
            "\n",
            "final policy\n",
            "|>|>|>|+|\n",
            "|^|#|^|-|\n",
            "|^|>|^|<|\n",
            "\n",
            "final values\n",
            "| 0.62| 0.80| 1.00| 0.00|\n",
            "| 0.45| 0.00| 0.75| 0.00|\n",
            "| 0.27| 0.41| 0.59| 0.30|\n",
            "\n",
            "visit counts\n",
            "| 7483| 7486|10689|    0|\n",
            "| 7510|    0| 3740|    0|\n",
            "|10920| 3721| 3723|  118|\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flV7mllUnqjC"
      },
      "source": [
        "### Q-learning\n",
        "\n",
        "* While helpful for exploring, $\\epsilon$-greedy is sub-optimal.\n",
        "* In comparison to SARSA, Q-learning target is\n",
        "$$r_{t+1} + \\gamma \\max_{a'}Q(s',a')$$\n",
        "instead of using the _actual next action_, we use the optimal _action we would have taken_ if we had chosen the current optimal action.\n",
        "\n",
        "* Q-learning is **_off-policy_**, actions are dictated by the $\\epsilon$-greedy policy, but we are learning the Q-function for the target policy greedily.\n",
        " * **_behaviour policy_**: dictates how we act in the environment\n",
        " * **_target policy_**: the policy that we are learning; it may not be same as the one we are using to determine our actions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "C6u-obxKnuIn",
        "outputId": "c7b2bb21-16cb-4767-a747-930c21f0a427"
      },
      "source": [
        "## TD-LEARNING: POLICY IMPROVEMENT - Q-learning\n",
        "CONVERGENCE_LIMIT = 1e-3\n",
        "GAMMA = 0.9\n",
        "MAX_EP_STEPS = 20\n",
        "ALPHA = .1\n",
        "\n",
        "## initialise environment\n",
        "grid = GridWorld5(step_cost=-.1)\n",
        "#no need to set a policy\n",
        "\n",
        "#grid.set_random_policy()\n",
        "print('init policy')\n",
        "grid.visualise_policy()\n",
        "\n",
        "\n",
        "## \n",
        "reward_hist = []\n",
        "#while True:\n",
        "for _ in range(10000):\n",
        "  ## start playing\n",
        "  grid.reset_location()\n",
        "\n",
        "  \n",
        "  rh = 0\n",
        "  while not grid.game_over():\n",
        "    #get action\n",
        "    current_action = grid.epsilon_greedy('Q') # this is `a`\n",
        "\n",
        "    #keep count of state-action visits\n",
        "    grid.StateActionVisitCounts[grid.CurrentState][current_action] += 1\n",
        "\n",
        "    #get reward\n",
        "    reward = grid.move(current_action) #here the agent has moved to s'\n",
        "    rh += reward\n",
        "\n",
        "    #update state value\n",
        "    q_prev = grid.StateActionValues[grid.PreviousState][current_action] #this is Q(s,a)\n",
        "    q_best = max(grid.StateActionValues[grid.CurrentState].values())\n",
        "\n",
        "    grid.StateActionValues[grid.PreviousState][current_action] = q_prev + ALPHA*(reward + GAMMA*q_best - q_prev)\n",
        "    \n",
        "    ## record change\n",
        "    #delta = max(delta,np.abs(grid.StateActionValues[grid.PreviousState][current_action] - q_prev))\n",
        "\n",
        "  reward_hist.append(rh)\n",
        "\n",
        "#here, we should have obtained Q*. Now, set policy according to Q*\n",
        "policy_dict = {s:{a:0 for a in grid.ActionSpace} for s in [(i,j) for i in range(grid.rows) for j in range(grid.cols)]}\n",
        "for state in grid.get_valid_states():\n",
        "  Qs = grid.StateActionValues[state]\n",
        "  max_a = []\n",
        "  max_val = max(list(Qs.values()))\n",
        "  for act,val in Qs.items():\n",
        "    if val == max_val:\n",
        "      max_a.append(act)\n",
        "  policy_dict[state][np.random.choice(max_a)] = 1 \n",
        "  grid.StateValues[state] = max_val\n",
        "grid.Policy = policy_dict\n",
        "\n",
        "\n",
        "\n",
        "grid.set_V_from_Q()\n",
        "grid.set_state_visit_counts()\n",
        "    \n",
        "print('\\nfinal policy')\n",
        "grid.visualise_policy()\n",
        "print('\\nfinal values')\n",
        "grid.visualise_values()\n",
        "print('\\nvisit counts')\n",
        "grid.visualise_state_visit_counts()\n",
        "print('\\n\\n')\n",
        "\n",
        "_ = plt.plot(reward_hist)\n",
        "  \n",
        "\n",
        "   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init policy\n",
            "|^|v|>|+|\n",
            "|>|#|v|-|\n",
            "|<|<|<|>|\n",
            "\n",
            "final policy\n",
            "|>|>|>|+|\n",
            "|^|#|^|-|\n",
            "|>|>|^|<|\n",
            "\n",
            "final values\n",
            "| 0.62| 0.80| 1.00| 0.00|\n",
            "| 0.46| 0.00| 0.80| 0.00|\n",
            "| 0.31| 0.46| 0.62| 0.46|\n",
            "\n",
            "visit counts\n",
            "|  317|  577|10526|    0|\n",
            "|  323|    0|10508|    0|\n",
            "|10836|10886|10824|  321|\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ePzrLWht37n"
      },
      "source": [
        "# **Function Approximation**\n",
        "\n",
        "\n",
        "* What has been discussed so far are tabular methods, where $V(s)$ and/or $Q(s,a)$ are stored in tables. However, realistically, it is not possible to store all possible states/actions in a table, as states/actions can be continuous.\n",
        "* Therefore, we implement **_function approximation_**, where instead of using tables, we use a supervised ML model to approximate state/action values, such that:\n",
        "$$\\hat{V}(s) = f(s,\\theta)$$\n",
        "Where $s$ represents the state, and $\\theta$ the model parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FYeLmzOrNfa"
      },
      "source": [
        "## Overview of Linear Function Approximation\n",
        "\n",
        "* In this example, we use Linear Regression models as a base example\n",
        "$$\\hat{y} = w^{T}X$$\n",
        "* For every model, we would need a loss function $J$, to indicate model performance. For Linear Regression, we utilise sum of squared error:\n",
        "$$J = (y - w^{T}X)^{T}(y - w^{T}X)$$\n",
        "* We solve for the weights of the model using the Loss function $J$, when the gradient of the loss would be at 0,\n",
        "$$\\nabla_{w}J = 0$$ \n",
        "* While in this case $\\nabla_{w}J$ can be solved in a closed form, $w = (X^{T}X)^{-1}(X^{T}y)$, in RL **_generally closed form solutions are not used_**. We therefore implement **_Gradient Ascent_** to minimise the loss:\n",
        "$$w = w + \\alpha \\nabla_{w}J$$\n",
        "Where\n",
        "$$\\nabla_{w}J = \\frac{2}{N}X^{T}(Xw-y)$$\n",
        " * Note that while Gradient Descent is usually used in supervised ML, for RL we tend to use Gradient Ascent.\n",
        "* As Stochastic/Batch Gradient Descent/Ascent can iteratively minimise the loss, by updating model weights one/a few data points at a time, this property allows for **_online updating_** for RL.\n",
        " * In the event that non-linear function approximation is required, while other ML models can do so, _not all ML models can do online updating_. Models that can learn with stochastic gradient descent/ascent are ideal.\n",
        "\n",
        "* We can also engineer features and **_expand the feature space_**, such that\n",
        "$$\\hat{y} = w^{T}\\phi(X)$$\n",
        "where $\\phi(X)$ represents the function that expands the feature space for dataset $X$. \n",
        "* Here we use the RBF kernel as an example\n",
        "$$\\phi(x) = \\exp \\bigl( - \\beta ||x - x_{i}||^{2}  \\bigr) $$\n",
        "which in essence takes the exponential of the euclidean distance between a point (a.k.a. row), $x_{i}$, and every other point (a.k.a. every other row) in $x$, weighted by some hyperparameter $\\beta$.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx7lc8ruOHOd"
      },
      "source": [
        "### environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf3MNWXTWpMq"
      },
      "source": [
        "class GridWorldEnv:\n",
        "  def __init__(self,rows=3,cols=4,start_position=(2,0),walls=[(1,1)],rewards_dict={(0,3):1,(1,3):-1},step_cost=0):\n",
        "    '''pass in wall as a list'''\n",
        "        \n",
        "    ## ENVIRONMENT MODEL\n",
        "    self.rows = rows\n",
        "    self.cols = cols\n",
        "\n",
        "    # create state space\n",
        "    self.StateSpace = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    self.Walls = walls\n",
        "    for wall in self.Walls: self.StateSpace.remove(wall) #set walls\n",
        "    \n",
        "    # define action space\n",
        "    self.ActionSpace = ('U','D','L','R')\n",
        "    \n",
        "    # define rewards\n",
        "    self.Rewards = rewards_dict\n",
        "    self.TerminalStates = list(self.Rewards.keys())\n",
        "\n",
        "    # define step cost\n",
        "    self.StepCost = step_cost\n",
        "\n",
        "    # visualise world\n",
        "    ## draw out cells, walls and reward locations.\n",
        "    self.World = np.array([[' ' for _ in range(cols)] for _ in range(rows)])\n",
        "    for wall in walls: self.World[wall[0],wall[1]] = '#'\n",
        "    for re in self.Rewards.keys():\n",
        "      if self.Rewards[re] > 0:\n",
        "        self.World[re[0],re[1]] = '+'\n",
        "      elif self.Rewards[re] < 0:\n",
        "        self.World[re[0],re[1]] = '-'\n",
        "\n",
        "    # set starting location\n",
        "    self.StartingState = start_position\n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## GETTINGS ##\n",
        "  def get_all_states(self):\n",
        "    return [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "  \n",
        "  def get_avail_actions(self):\n",
        "    return self.ActionSpace\n",
        "  \n",
        "  def get_starting_state(self):\n",
        "    return self.StartingState\n",
        "  \n",
        "  def get_valid_states(self):\n",
        "    available_states = [(i,j) for i in range(self.rows) for j in range(self.cols)]\n",
        "    for wall in self.Walls: available_states.remove(wall) #set walls\n",
        "    for term in self.TerminalStates: available_states.remove(term) #set walls\n",
        "    return available_states\n",
        "\n",
        "  def get_next_state(self,state,action):\n",
        "    next_state = list(state)\n",
        "    if action == 'U':\n",
        "      next_state[0] -= 1\n",
        "    elif action == 'D':\n",
        "      next_state[0] += 1\n",
        "    elif action == 'L':\n",
        "      next_state[1] -= 1\n",
        "    elif action == 'R':\n",
        "      next_state[1] += 1\n",
        "    \n",
        "    if tuple(next_state) in self.StateSpace:\n",
        "      return tuple(next_state)\n",
        "    else:\n",
        "      return tuple(state)\n",
        "  \n",
        "  def get_state_reward(self,next_state):\n",
        "    return self.Rewards.get(next_state,0) #return defined rewards\n",
        "\n",
        "  def get_reward(self,next_state):\n",
        "    return self.Rewards.get(next_state,self.StepCost) #return defined rewards\n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## UTILS ##\n",
        "  def is_terminal(self,state):\n",
        "    return state in self.TerminalStates\n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "\n",
        "  ## VISUALISERS ##\n",
        "  def visualise_world(self,view_agent_loc=True):\n",
        "    world = self.World.copy()\n",
        "\n",
        "    ## mark agent location\n",
        "    if view_agent_loc:\n",
        "      r,c = self.CurrentState\n",
        "      if self.CurrentState == self.PreviousState:\n",
        "        world[r,c] = '*'\n",
        "      else:\n",
        "        world[r,c] = 'o'\n",
        "    \n",
        "    ## display\n",
        "    for r in world: \n",
        "      print('|'+'%s|' * len(r) %tuple(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM1tbesuB9Ri"
      },
      "source": [
        "### agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl8N_jT0uk6r"
      },
      "source": [
        "class GridPlayer():\n",
        "  def __init__(self):\n",
        "    self.name = 'Agent'\n",
        "  \n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## STARTUP FUNCTIONS ##\n",
        "\n",
        "  def sample_unknown_environment(self,grid,n_eps=10000):\n",
        "    # get environment properties\n",
        "    self.StartingState = grid.get_starting_state()\n",
        "    self.ActionSpace = grid.get_avail_actions()\n",
        "    \n",
        "    # start sampling states, to get a representation of available states\n",
        "    self.Samples = []\n",
        "    for _ in range(n_eps):\n",
        "      s = self.StartingState\n",
        "      while not grid.is_terminal(s):\n",
        "        #draw action\n",
        "        act = np.random.choice(self.ActionSpace)\n",
        "\n",
        "        #concatenate\n",
        "        sa = tuple(list(s) + [1 if act==a else 0 for a in self.ActionSpace])\n",
        "        self.Samples.append(sa)\n",
        "\n",
        "        #move to next state\n",
        "        s = grid.get_next_state(s,act)\n",
        "      \n",
        "      #at terminal state, concatenate into samples but with dummy action\n",
        "      act = np.random.choice(self.ActionSpace)\n",
        "      sa = tuple(list(s) + [1 if act==a else 0 for a in self.ActionSpace])\n",
        "      self.Samples.append(sa)\n",
        "      \n",
        "    # collate available states (including terminal states for now)\n",
        "    self.AvailableStates = list(set([(list(s)[0],list(s)[1]) for s in self.Samples]))\n",
        "\n",
        "    # represent world\n",
        "    rows = []\n",
        "    cols = []\n",
        "    for states in self.AvailableStates:\n",
        "      r,c = states\n",
        "      rows.append(r)\n",
        "      cols.append(c)\n",
        "\n",
        "    self.AvailRows = max(rows)+1\n",
        "    self.AvailCols = max(cols)+1\n",
        "    self.World = [(i,j) for i in range(self.AvailRows) for j in range(self.AvailCols)] #largest possible state space\n",
        "\n",
        "    for s in self.World: #define Walls in the environment\n",
        "      if s not in self.AvailableStates:\n",
        "        if not hasattr(self,'Walls'):\n",
        "          self.Walls=[]\n",
        "        self.Walls.append(s) \n",
        "\n",
        "    # represent current state\n",
        "    self.PreviousState = self.StartingState\n",
        "    self.CurrentState = self.StartingState\n",
        "\n",
        "    # collate rewards & terminal states\n",
        "    for state in self.AvailableStates:\n",
        "      r = grid.get_state_reward(state)\n",
        "      if r != 0:\n",
        "        if not hasattr(self,'Rewards'):\n",
        "          self.Rewards = {}\n",
        "        self.Rewards[state] = r\n",
        "    if hasattr(self,'Rewards'): self.TerminalStates = list(self.Rewards.keys())\n",
        "    \n",
        "    # finally, remove terminal states from available states\n",
        "    if hasattr(self,'TerminalStates'):\n",
        "      for state in self.AvailableStates:\n",
        "        if state in self.TerminalStates:\n",
        "          self.AvailableStates.remove(state)\n",
        "  \n",
        "  ## reset agent location back to start\n",
        "  def reset_agent(self):\n",
        "    self.CurrentState = self.StartingState\n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## POLICY ##\n",
        "  \n",
        "  # set policy equal for all options\n",
        "  def set_equil_policy(self):\n",
        "    if hasattr(self,'ActionSpace'):\n",
        "      self.Policy = {s:{a:1/len(self.ActionSpace) for a in self.ActionSpace} for s in [(i,j) for i in range(self.AvailRows) for j in range(self.AvailCols)]}\n",
        "    else:\n",
        "      print('Policy Generation Error: agent has no knowledge of environment')\n",
        "  \n",
        "  # set random policy\n",
        "  def set_random_policy(self):\n",
        "    if hasattr(self,'ActionSpace'):\n",
        "      self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.AvailRows) for j in range(self.AvailCols)]}\n",
        "      for state in self.Policy:\n",
        "        a_ = np.random.choice(self.ActionSpace)\n",
        "        self.Policy[state][a_] = 1\n",
        "    else:\n",
        "      print('Policy Generation Error: agent has no knowledge of environment')\n",
        "\n",
        "  # set best policy\n",
        "  def set_best_policy(self):\n",
        "    self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.AvailRows) for j in range(self.AvailCols)]}\n",
        "    fixed_policy = {(0, 0): {'R':1},\n",
        "                    (0, 1): {'R':1},\n",
        "                    (0, 2): {'R':1},\n",
        "                    (1, 0): {'U':1},\n",
        "                    (1, 2): {'U':1},\n",
        "                    (2, 0): {'U':1},\n",
        "                    (2, 1): {'R':1},\n",
        "                    (2, 2): {'U':1},\n",
        "                    (2, 3): {'L':1}}\n",
        "    for state,action in fixed_policy.items():\n",
        "      for act,val in action.items():\n",
        "        self.Policy[state][act] = val\n",
        "\n",
        "\n",
        "  # set test policy (according to lectures)\n",
        "  def set_test_policy(self):\n",
        "    self.Policy = {s:{a:0 for a in self.ActionSpace} for s in [(i,j) for i in range(self.AvailRows) for j in range(self.AvailCols)]}\n",
        "    fixed_policy = {(0, 0): {'R':1},\n",
        "                    (0, 1): {'R':1},\n",
        "                    (0, 2): {'R':1},\n",
        "                    (1, 0): {'U':1},\n",
        "                    (1, 2): {'R':1},\n",
        "                    (2, 0): {'U':1},\n",
        "                    (2, 1): {'R':1},\n",
        "                    (2, 2): {'R':1},\n",
        "                    (2, 3): {'U':1}}\n",
        "    for state,action in fixed_policy.items():\n",
        "      for act,val in action.items():\n",
        "        self.Policy[state][act] = val\n",
        "\n",
        "\n",
        "  # epsilon-greedy policy\n",
        "  def epsilon_greedy(self,state,based_on='policy', eps=.1):\n",
        "    #for majority of the time, return best action (with ties broken randomly)\n",
        "    if np.random.rand() < (1 - eps): \n",
        "      if based_on == 'policy':\n",
        "        max_a = [] \n",
        "        max_val = max(self.Policy[state].values())\n",
        "        for act,val in self.Policy[state].items():\n",
        "          if val == max_val:\n",
        "            max_a.append(act)  \n",
        "      elif based_on == 'Q': #action based on best State-action values\n",
        "        #first, get maximum Q-value\n",
        "        values = []\n",
        "        max_val = float('-inf')\n",
        "        for act in self.ActionSpace:\n",
        "          sa = tuple(list(state) + [1 if act==a else 0 for a in self.ActionSpace])\n",
        "          x = self.Featurizer.transform([sa])[0]\n",
        "          val = x @ self.FuncWeights\n",
        "          values.append((act,val))\n",
        "          max_val = max(val,max_val)\n",
        "        \n",
        "        #then, find actions which are at the maximum value\n",
        "        max_a = []\n",
        "        for act,val in values:\n",
        "          if val == max_val:\n",
        "            max_a.append(act)\n",
        "      return np.random.choice(max_a) \n",
        "    #otherwise random action\n",
        "    else: \n",
        "      return np.random.choice(self.ActionSpace)\n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## VALUES BY FUNCTION APPROXIMATION ##\n",
        "\n",
        "  def approximate_model(self,value_flag='Q'):\n",
        "    '''type is either V for state values or Q for state-action values'''\n",
        "    self.StateVisits = {s:0 for s in self.World}\n",
        "    # linear function approximator\n",
        "    self.Featurizer = RBFSampler()\n",
        "    if value_flag == 'V':\n",
        "      self.EncounteredStates = [(list(s)[0],list(s)[1]) for s in self.Samples]\n",
        "      self.Featurizer.fit(self.EncounteredStates)\n",
        "    elif value_flag == 'Q':\n",
        "      self.Featurizer.fit(self.Samples)\n",
        "    self.FuncWeights = np.zeros(self.Featurizer.n_components) #this assumes linear model\n",
        "\n",
        "\n",
        "  def approximate_values(self,value_flag='Q'):\n",
        "    self.StateValues = {s:0 for s in self.World}\n",
        "    for state in self.AvailableStates:\n",
        "      if value_flag == 'V':\n",
        "        x = self.Featurizer.transform([state])[0]\n",
        "        self.StateValues[state] = x @ self.FuncWeights\n",
        "      elif value_flag == 'Q':\n",
        "        values = []\n",
        "        for act in self.ActionSpace:\n",
        "          sa = tuple(list(state) + [1 if act==a else 0 for a in self.ActionSpace])\n",
        "          x = self.Featurizer.transform([sa])[0]\n",
        "          values.append(x @ self.FuncWeights)\n",
        "        self.StateValues[state] = max(values)\n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "  ## VISUALISERS ##\n",
        "\n",
        "  # \n",
        "  def visualise_world(self):\n",
        "    if hasattr(self,'World'):\n",
        "      ##build environment\n",
        "      world = np.array([[' ' for _ in range(self.AvailCols)] for _ in range(self.AvailRows)])\n",
        "      \n",
        "      # mark starting location\n",
        "      if hasattr(self,'CurrentState'):\n",
        "        r,c = self.CurrentState\n",
        "        world[r,c] = '*'\n",
        "      \n",
        "      # mark walls\n",
        "      if hasattr(self, 'Walls'):\n",
        "        for wall in self.Walls: \n",
        "          world[wall[0],wall[1]] = '#'\n",
        "      \n",
        "      # mark rewards\n",
        "      if hasattr(self, 'Rewards'):\n",
        "        for rloc,val in self.Rewards.items():\n",
        "          r,c = rloc\n",
        "          if val > 0:\n",
        "            world[r,c] = '+'\n",
        "          elif val < 0:\n",
        "            world[r,c] = '-'\n",
        "\n",
        "      # display\n",
        "      for r in world: \n",
        "        print('|'+'%s|' * len(r) %tuple(r))\n",
        "    else:\n",
        "      print('World Visualisation Error: agent has no knowledge of environment')\n",
        "\n",
        "\n",
        "  # values\n",
        "  def visualise_values(self):\n",
        "    if hasattr(self,'StateValues'):\n",
        "      values = np.zeros((self.AvailRows,self.AvailCols))\n",
        "      for state,vals in self.StateValues.items():\n",
        "        r,c = state\n",
        "        values[r,c] = vals\n",
        "      \n",
        "      for rows in values:\n",
        "        print('|',end=\"\")\n",
        "        for c in rows:\n",
        "          if c >= 0:\n",
        "            print(' %.2f|' % c, end=\"\")\n",
        "          else:\n",
        "            print('%.2f|' % c, end=\"\")\n",
        "        print('\\n',end=\"\")\n",
        "    else:\n",
        "      print('State-Value Visualisation Error: agent has no knowledge of state values')\n",
        "\n",
        "  # policy\n",
        "  def visualise_policy(self):\n",
        "    if hasattr(self,'Policy'):\n",
        "      polmap = np.array([[' ' for _ in range(self.AvailCols)] for _ in range(self.AvailRows)])\n",
        "      \n",
        "      #get only valid policies\n",
        "      valid_policies = self.Policy.copy()\n",
        "      for wall in self.Walls: valid_policies.pop(wall,None) #set walls\n",
        "      for term in self.TerminalStates: valid_policies.pop(term,None) #set walls\n",
        "      \n",
        "      #fill in cells with arrows depicting policies\n",
        "      for state,act in valid_policies.items():\n",
        "        r,c = state\n",
        "        a = []\n",
        "        for ak,vk in act.items():\n",
        "          if vk == max(act.values()):\n",
        "            a.append(ak)\n",
        "        action = np.random.choice(a)\n",
        "        if action == 'U':\n",
        "          polmap[r,c] = '^'\n",
        "        elif action == 'D':\n",
        "          polmap[r,c] = 'v'\n",
        "        elif action == 'L':\n",
        "          polmap[r,c] = '<'\n",
        "        elif action == 'R':\n",
        "          polmap[r,c] = '>'\n",
        "      \n",
        "      #fill in rewards\n",
        "      if hasattr(self,'Rewards'):\n",
        "        for state,reward in self.Rewards.items():\n",
        "          r,c = state\n",
        "          if reward > 0:\n",
        "            polmap[r,c] = '+'\n",
        "          elif reward < 0:\n",
        "            polmap[r,c] = '-'\n",
        "\n",
        "      #fill in walls\n",
        "      if hasattr(self,'Walls'):\n",
        "        for r,c in self.Walls:\n",
        "          polmap[r,c] = '#'\n",
        "\n",
        "      for p in polmap: print('|'+'%s|' * len(p) %tuple(p))\n",
        "    else:\n",
        "      print('Policy Visualisation Error: agent has no knowledge of policy')\n",
        "  ##--------------------------------------------------------------------##\n",
        "  \n",
        "  ##\n",
        "  def predictV(self,state): \n",
        "    x = self.Featurizer.transform([state])[0]\n",
        "    return x @ self.FuncWeights\n",
        "\n",
        "  def gradientV(self,state): \n",
        "    x = self.Featurizer.transform([state])[0]\n",
        "    return x\n",
        "\n",
        "  def predictQ(self,state,action): \n",
        "    sa = tuple(list(state) + [1 if action==a else 0 for a in self.ActionSpace])\n",
        "    x = self.Featurizer.transform([sa])[0]\n",
        "    return x @ self.FuncWeights\n",
        "\n",
        "  def gradientQ(self,state,action): \n",
        "    sa = tuple(list(state) + [1 if action==a else 0 for a in self.ActionSpace])\n",
        "    x = self.Featurizer.transform([sa])[0]\n",
        "    return x\n",
        "\n",
        "\n",
        "  ##--------------------------------------------------------------------##\n",
        "  ##--------------------------------------------------------------------##\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RPIWE4BueNz"
      },
      "source": [
        "## Approximation methods for prediction\n",
        "\n",
        "* In our example, we approximate/transform the state $s$ to a feature vector $x$ as:\n",
        "$$x = \\phi(s)$$\n",
        "* We then model our value function as follows:\n",
        "$$\\hat{V}_{\\pi}(s) = w^{T}\\phi(s)$$\n",
        " * This therefore extands the search for state values into a continuous space, as we no longer have to refer to a table for $V_{\\pi}(s)$, but instead compute it\n",
        " * $s$ can now be either  a discrete or continuous value.\n",
        "* We improve our estimates by comparing $\\hat{V}_{\\pi}(s)$ to our return $G$,\n",
        "$$\\begin{aligned}\n",
        "J &= \\bigl(G - \\hat{V}_{\\pi}(s) \\bigr)^{2}\n",
        "\\\\ &= \\bigl(G - w^{T}\\phi(s) \\bigr)^{2}\n",
        "\\end{aligned}$$\n",
        "and we attempt to minimise the loss $J$ via stochastic gradient ascent, where the gradient is\n",
        "$$\\nabla_{w}J = 2(G-w^{T}x)x$$\n",
        " * note that we are doing gradient _ascent_, not _descent_, as is typical during RL. This is where the arrangement of $G$ and $w^{T}\\phi(s)$ matters.\n",
        "* We can therefore update our model parameters incrementally via\n",
        "$$w = w + \\alpha(G-w^{T}x)x$$\n",
        "where we ignore the constant $2$ in the derivative, and absorbe it instead into our constant learning rate $\\alpha$\n",
        "* One point of comparison between the tabular approach and function approximation approach is that, while in the tabular case, when we update $V(s)$ the vector of $V$ only changes at the entry for state $s$. However, in the function approximation case, when we update $w$, it can possibly change $V$ for all states $s$.\n",
        "\n",
        "---\n",
        "**Tabular methods & function approximation**\n",
        "\n",
        "* Tabular methods are a _special case_ of linear function approximation, where we use one-hot encoding as the expansion function $\\phi(s)$, such that if:\n",
        "  $$ \\mathcal{S} \\in \\{s_{1},s_{2},...,s_{D}\\}$$\n",
        "  then the one-hot expansion is:\n",
        "  $$\\begin{aligned}\n",
        "  \\phi(s_{1}) &= (1,0,0,...)\n",
        "  \\\\ \\phi(s_{2}) &= (0,1,0,...)\n",
        "  \\\\ ...\n",
        "  \\\\ \\phi(s_{D}) &= (0,0,...,1)\n",
        "  \\end{aligned}$$\n",
        "\n",
        "* State values are then estimated using the same formula $\\hat{V}_{\\pi}(s) = w^{T}\\phi(s)$, where\n",
        "  $$\\begin{aligned}\n",
        "  \\hat{V}_{\\pi}(s_{1}) &= (w_{1},w_{2},...,w_{D}) \\cdot (1,0,0,...) = w_{1}\n",
        "  \\\\ \\hat{V}_{\\pi}(s_{2}) &= (w_{1},w_{2},...,w_{D}) \\cdot (0,1,0,...) = w_{2}\n",
        "  \\\\ ...\n",
        "  \\\\ \\hat{V}_{\\pi}(s_{D}) &= (w_{1},w_{2},...,w_{D}) \\cdot (0,0,...,1) = w_{D}\n",
        "  \\end{aligned}$$\n",
        "  and each state therefore has its own independent estimate\n",
        "* And therefore the gradient will be 1 for the state of interest, and 0 for all the other states, and the update rule is then\n",
        "$$w_{i} = w_{i} + \\alpha(G-w_{i}) \\cdot 1$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "kArrkd_3pQwG",
        "outputId": "b95c3893-9830-4563-928f-b5f6712901ed"
      },
      "source": [
        "## TD-learning with func approx\n",
        "\n",
        "#setup\n",
        "grid = GridWorldEnv()\n",
        "agent = GridPlayer()\n",
        "GAMMA = 0.9\n",
        "ALPHA = 0.01\n",
        "\n",
        "#here, agent plays a few rounds in the environment to sample possible states\n",
        "agent.sample_unknown_environment(grid)\n",
        "\n",
        "#approximate state values by linear function\n",
        "agent.approximate_model('V')\n",
        "\n",
        "#set a policy\n",
        "agent.set_test_policy()\n",
        "agent.visualise_policy()\n",
        "\n",
        "#\n",
        "mse_per_episode = []\n",
        "for _ in range(10000):\n",
        "  agent.reset_agent()\n",
        "  Vs = agent.predictV(agent.CurrentState)\n",
        "  n_steps = 0\n",
        "  episode_err = 0\n",
        "\n",
        "  while not grid.is_terminal(agent.CurrentState):\n",
        "\n",
        "    #keep record of previous state\n",
        "    agent.PreviousState = agent.CurrentState\n",
        "\n",
        "    #get action\n",
        "    action = agent.epsilon_greedy(agent.CurrentState) #action from current state (according to policy)\n",
        "    \n",
        "    #get next state, move & obtain reward\n",
        "    next_state = grid.get_next_state(agent.CurrentState,action)\n",
        "    agent.CurrentState = next_state\n",
        "    reward = grid.get_reward(agent.CurrentState)\n",
        "    \n",
        "    # get target\n",
        "    if grid.is_terminal(agent.CurrentState):\n",
        "      target = reward\n",
        "    else:\n",
        "      Vs2 = agent.predictV(agent.CurrentState)\n",
        "      target = reward + GAMMA* Vs2\n",
        "\n",
        "    # update approximator in agent\n",
        "    g = agent.gradientV(agent.PreviousState) #gradient is from previous state\n",
        "    err = target - Vs\n",
        "    agent.FuncWeights += ALPHA * err * g\n",
        "\n",
        "    # accumulate error\n",
        "    n_steps += 1\n",
        "    episode_err += err**2\n",
        "\n",
        "    # update value of state\n",
        "    Vs = Vs2\n",
        "\n",
        "  mse = episode_err/n_steps\n",
        "  mse_per_episode.append(mse)\n",
        "\n",
        "\n",
        "##\n",
        "_ = plt.plot(mse_per_episode)\n",
        "\n",
        "agent.approximate_values('V')\n",
        "agent.visualise_values()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|>|>|>| |\n",
            "|^| |>| |\n",
            "|^|>|>|^|\n",
            "| 0.73| 0.83| 0.94| 0.00|\n",
            "| 0.66| 0.00|-0.77| 0.00|\n",
            "| 0.55|-0.67|-0.93|-0.88|\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9wMScOuuiFd"
      },
      "source": [
        "## Approximation methods for control\n",
        "\n",
        "* We previously approximated $V(s)$, now we have to approximate $Q(s,a)$. We can do so similarly:\n",
        "$$\\text{let } x = \\phi(s,a), \\;\\text{then }  \\hat{Q}(s,a) = w^{T}x$$\n",
        "* Note however that we have to keep track of actions now. As our actions are discrete, we can on-hot encode them, and concatenate them to the states, i.e\n",
        "assuming our action space is $(\\uparrow,\\downarrow,\\leftarrow,\\rightarrow)$, if we were at state $(1,2)$ and moved $\\downarrow$, then we can represent \n",
        "$$\\hat{Q} \\bigl((1,2),\\downarrow \\bigr) = \\hat{Q}\\bigl((1,2,0,1,0,0)\\bigr)$$\n",
        "* Once we've represented our state actions in a row, we can follow the same update rules:\n",
        "$$J = \\bigl( G -  \\hat{Q}(s,a)\\bigr)^{2}$$\n",
        "$$\\nabla_{w}J = -2(G-w^{T}x)x$$\n",
        "$$w = w + \\alpha(G-w^{T}x)x $$\n",
        "* As a reminder, Q-learning target is\n",
        "$$G = r + \\gamma \\max_{a'}\\hat{Q}(s',a')$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "BC39ARP2rKSb",
        "outputId": "aadb354f-d1cc-40bb-938e-3b08283d5fcf"
      },
      "source": [
        "## Q-learning with func approx - Control\n",
        "\n",
        "#setup\n",
        "grid = GridWorldEnv(step_cost=-.1)\n",
        "agent = GridPlayer()\n",
        "GAMMA = 0.9\n",
        "ALPHA = 0.01\n",
        "\n",
        "#here, agent plays a few rounds in the environment to sample possible states\n",
        "agent.sample_unknown_environment(grid)\n",
        "\n",
        "#approximate state values by linear function\n",
        "agent.approximate_model('Q')\n",
        "\n",
        "#set a policy\n",
        "agent.set_equil_policy()\n",
        "agent.visualise_policy()\n",
        "\n",
        "#\n",
        "reward_per_episode = []\n",
        "for _ in range(20000):\n",
        "  agent.reset_agent()\n",
        "  agent.StateVisits[agent.CurrentState] += 1\n",
        "\n",
        "  episode_reward = 0\n",
        "  while not grid.is_terminal(agent.CurrentState):\n",
        "    #keep record of previous state\n",
        "    agent.PreviousState = agent.CurrentState\n",
        "\n",
        "    #get action\n",
        "    action = agent.epsilon_greedy(agent.CurrentState,'Q') #action from current state (according to policy)\n",
        "\n",
        "    #get next state, move & obtain reward\n",
        "    next_state = grid.get_next_state(agent.CurrentState,action)\n",
        "    agent.CurrentState = next_state #move agent to new state\n",
        "    reward = grid.get_reward(next_state)\n",
        "    \n",
        "    # get target\n",
        "    if grid.is_terminal(agent.CurrentState):\n",
        "      target = reward\n",
        "    else:\n",
        "      Qs2 = []\n",
        "      for next_action in agent.ActionSpace:\n",
        "        Qs2.append(agent.predictQ(agent.CurrentState,next_action)) #this is a list of all values of Q(s',a')\n",
        "      target = reward + GAMMA* max(Qs2)\n",
        "\n",
        "    # update approximator in agent\n",
        "    g = agent.gradientQ(agent.PreviousState,action) #gradient is from previous state & action\n",
        "    err = target - agent.predictQ(agent.PreviousState,action)\n",
        "    agent.FuncWeights += ALPHA * err * g\n",
        "\n",
        "    # accumulate reward & state visit counts\n",
        "    episode_reward += reward\n",
        "    agent.StateVisits[agent.CurrentState] += 1\n",
        "\n",
        "  reward_per_episode.append(episode_reward)\n",
        "\n",
        "#here, we should have obtained Q*. Now, set policy according to Q*\n",
        "policy_dict = {s:{a:0 for a in agent.ActionSpace} for s in [(i,j) for i in range(agent.AvailRows) for j in range(agent.AvailCols)]}\n",
        "for state in agent.AvailableStates:\n",
        "  values = []\n",
        "  maxQ = float('-inf')\n",
        "  for action in agent.ActionSpace:\n",
        "    Qs = agent.predictQ(state,action)\n",
        "    values.append((action,Qs))\n",
        "    maxQ = max(Qs,maxQ)\n",
        "  \n",
        "  max_a = []\n",
        "  for act,val in values:\n",
        "    if val == maxQ:\n",
        "      max_a.append(act)\n",
        "  policy_dict[state][np.random.choice(max_a)] = 1\n",
        "agent.Policy = policy_dict \n",
        "\n",
        "##\n",
        "_ = plt.plot(reward_per_episode)\n",
        "\n",
        "agent.approximate_values('Q')\n",
        "print('\\nfinal values')\n",
        "agent.visualise_values()\n",
        "print('\\nfinal policy')\n",
        "agent.visualise_policy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|<|<|^|+|\n",
            "|<|#|v|-|\n",
            "|<|^|^|<|\n",
            "\n",
            "final values\n",
            "| 0.62| 0.80| 1.00| 0.00|\n",
            "| 0.46| 0.00| 0.78| 0.00|\n",
            "| 0.31| 0.16| 0.04| 0.03|\n",
            "\n",
            "final policy\n",
            "|>|>|>|+|\n",
            "|^|#|^|-|\n",
            "|^|<|<|>|\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}